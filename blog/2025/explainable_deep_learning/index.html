<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Explicabilité en deep learning | Camille Barboule </title> <meta name="author" content="Camille Barboule"> <meta name="description" content="Explcabilité des modèles de deep learning"> <meta name="keywords" content="NLP, IR, Agents, Deep-Learning, XAI"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%9A&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://camillebrl.github.io/blog/2025/explainable_deep_learning/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightbox2@2.11.5/dist/css/lightbox.min.css" integrity="sha256-uypRbsAiJcFInM/ndyI/JHpzNe6DtUNXaWEUWEPfMGo=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@5.4.4/dist/photoswipe.min.css" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/spotlight.js@0.7.8/dist/css/spotlight.min.css" integrity="sha256-Dsvkx8BU8ntk9Iv+4sCkgHRynYSQQFP6gJfBN5STFLY=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/venobox@2.1.8/dist/venobox.min.css" integrity="sha256-ohJEB0/WsBOdBD+gQO/MGfyJSbTUI8OOLbQGdkxD6Cg=" crossorigin="anonymous"> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <style>.toc-list{list-style:none;padding-left:0}.toc-list ul{list-style:none;padding-left:1.5em}.toc-list li{margin:.5em 0}.toc-list a{text-decoration:none;color:inherit}.toc-list a:hover{text-decoration:underline}d-article>*:first-child{margin-top:0!important}d-contents+h1,d-contents+h2,d-contents+h3,d-contents+h4,d-contents+h5,d-contents+h6,d-contents+p{margin-top:2rem!important}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Explicabilité en deep learning",
            "description": "Explcabilité des modèles de deep learning",
            "published": "August 15, 2025",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Camille</span> Barboule </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Explicabilité en deep learning</h1> <p>Explcabilité des modèles de deep learning</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div id="toc-container" class="toc-list"> </div> </nav> </d-contents> <h1 id="analyse-des-données">Analyse des données</h1> <h2 id="représentativité-des-données">Représentativité des données</h2> <p>Nous allons détailler l’approche <a href="https://github.com/deel-ai/xplique/blob/master/xplique/metrics/representativity.py" rel="external nofollow noopener" target="_blank">MeGe de la librairie Xplain de Deel-ai</a> qui évalue la représentativité des données via un protocole “K modèles / K splits”. L’idée centrale repose sur le fait que si les données sont bien représentatives (couvrent le support/les variations pertinentes) et si l’explicabilité de la génération du modèle est stable, alors <strong>les explications produites par des modèles entraînés sur des sous-échantillons différents devraient être semblables lorsque les modèles aboutissent à la même prédiction correcte</strong>. À l’inverse, les <strong>explications devraient s’écarter lorsque les modèles prédisent des classes différentes</strong>.</p> <p>On dispose d’un jeu de données $\mathcal{D}={(x_n,y_n)}_{n=1}^N$, où $y_n$ est <strong>one-hot</strong> pour la classification. Le code impose un entier $K$ tel que $K$ divise $N$, puis découpe $\mathcal{D}$ en $K$ splits de même taille $m=N/K$ : \(\mathcal{D} = \bigsqcup_{i=1}^K S_i, \qquad |S_i|=m.\)</p> <p>Pour chaque $i\in{1,\dots,K}$, on entraîne un modèle $M_i$ avec les données hors du split $S_i$ : \(M_i \leftarrow \text{learning\_algorithm}\big(\underbrace{\mathcal{D}\setminus S_i}_{\text{train}}, \underbrace{S_i}_{\text{validation/test}}\big).\)</p> <p>e protocole “K modèles / K splits” ?**<br> Il imite une <strong>perturbation des données d’entraînement</strong> : chaque modèle voit une <strong>version partielle</strong> du jeu, ce qui permet de <strong>sonder la stabilité des explications</strong> vis-à-vis de variations réalistes d’échantillonnage (mesure indirecte de la <strong>représentativité des données</strong> et de la <strong>robustesse de l’explication</strong>).</p> <h2 id="complétude-des-données-lapproche-reco-de-la-librairie-xplain-de-deel-ai-qui-évalue-la-représentativité-des-données">Complétude des données: l’approche <a href="https://github.com/deel-ai/xplique/blob/master/xplique/metrics/representativity.py" rel="external nofollow noopener" target="_blank">ReCo de la librairie Xplain de Deel-ai</a> qui évalue la représentativité des données</h2> <h1 id="evaluation-de-la-robustesse-du-modèle">Evaluation de la robustesse du modèle</h1> <p><a href="https://github.com/deel-ai/deel-lip" rel="external nofollow noopener" target="_blank">deel-lip de Deel-IA</a></p> <p>En vérification/robustesse, on cherche des <strong>bornes déterministes</strong> qui garantissent ce que le modèle <strong>ne peut pas</strong> faire quand l’entrée est perturbée dans un rayon (\varepsilon) (p. ex. attaques adversariales (|\delta|_p \le \varepsilon)). On borne :</p> <ul> <li> <strong>Les sorties</strong> (f(x)) (logits/scores) : obtenir des <strong>intervalles</strong> qui contiennent (f(x+\delta)) pour <strong>toutes</strong> (\delta) admissibles.</li> <li> <strong>Le gradient/Jacobien</strong> (J_f(x)=\frac{\partial f}{\partial x}) : contrôler la <strong>sensibilité locale</strong>. Borner (|J_f(x)|) <strong>implique</strong> borner la variation des sorties.</li> <li> <strong>La perte</strong> (L(f(x),y)) : certaines méthodes bornent directement une <strong>perte robuste</strong> (majorant/minorant du pire cas).</li> </ul> <blockquote> <p><strong>À quoi ça sert ?</strong></p> <ul> <li> <strong>Certifier</strong> qu’aucune perturbation (|\delta|_p\le\varepsilon) ne change la prédiction (certificat de robustesse).</li> <li> <strong>Entraîner</strong> le modèle sous contrainte (régularisations/architectures) pour <strong>augmenter</strong> la robustesse certifiée.</li> <li> <strong>Auditer</strong> la stabilité des explications basées gradients (sensibilité locale).</li> </ul> </blockquote> <h2 id="1-constante-de-lipschitz-via-deel-lip">1) Constante de <strong>Lipschitz</strong> (via <code class="language-plaintext highlighter-rouge">deel-lip</code>)</h2> <h3 id="définition">Définition</h3> <p>Pour (f:(\mathbb{R}^n,|\cdot|<em>p)\to(\mathbb{R}^m,|\cdot|_q)), (f) est (K)-Lipschitz si [ |f(x)-f(y)|_q \le K\,|x-y|_p,\quad \forall x,y. ] Le plus petit (K) est (\mathrm{Lip}(f)). Si (f) est différentiable, [ \mathrm{Lip}(f)\;\le\;\sup</em>{x}\,|J_f(x)|_{p\to q}. ]</p> <p><strong>Conséquence « marge certifiée ».</strong><br> Soit la <strong>marge</strong> (m(x)=f_y(x)-\max_{j\ne y}f_j(x)). Si chaque logit est (K)-Lipschitz, alors pour toute (|\delta|_p \le \varepsilon), [ m(x+\delta)\;\ge\; m(x) - 2K\varepsilon. ] Donc si (m(x) &gt; 2K\varepsilon), la prédiction est <strong>certifiée</strong> inchangée dans la boule (\varepsilon).</p> <h3 id="comment-deel-lip-calculecontrôle-k">Comment <code class="language-plaintext highlighter-rouge">deel-lip</code> calcule/contrôle (K)</h3> <p><code class="language-plaintext highlighter-rouge">deel-lip</code> (et son pendant PyTorch <code class="language-plaintext highlighter-rouge">deel-torchlip</code>) vise à <strong>construire des réseaux (k)-Lipschitz par design</strong> en contrôlant la norme d’opérateur des couches et en choisissant des activations 1-Lipschitz.</p> <ul> <li> <strong>Couches linéaires (denses/conv) avec contrainte spectrale.</strong> <ul> <li> <strong>Power iteration</strong> : approximer la plus grande valeur singulière (\sigma_{\max}(W)) et <strong>la normaliser</strong> (puis <strong>rescaler</strong> vers la cible (k)).</li> <li> <strong>Björck orthonormalization</strong> : itérer pour rapprocher (W) d’une matrice (quasi-)orthonormale (singulières (\approx 1)), puis appliquer un <strong>facteur d’échelle</strong> pour viser (|W|_{\text{op}}\approx k).</li> </ul> </li> <li> <p><strong>Convolutions : RKO (Reshaped Kernel Orthogonalization).</strong><br> Remodeler le noyau de conv en matrice, appliquer power iteration + Björck pour contrôler la <strong>norme d’opérateur effective</strong> de la convolution, puis rescaler.</p> </li> <li> <p><strong>Activations 1-Lipschitz.</strong><br> Ex. <code class="language-plaintext highlighter-rouge">GroupSort</code>, <code class="language-plaintext highlighter-rouge">FullSort</code>, <code class="language-plaintext highlighter-rouge">MaxMin</code>, <code class="language-plaintext highlighter-rouge">Householder</code>, etc. Si chaque activation est 1-Lipschitz et chaque couche linéaire est (k_\ell)-Lipschitz, [ \mathrm{Lip}(f)\;\le\;\prod_{\ell=1}^L k_\ell. ]</p> </li> <li> <strong>Métriques &amp; pertes adaptées.</strong><br> La librairie expose des <strong>métriques</strong> pour suivre (\sigma_{\max}) / lip de couche et des <strong>pertes</strong> (p. ex. variantes type HKR) pour favoriser des classifieurs <strong>certifiables</strong>.</li> </ul> <blockquote> <p><strong>Calcul d’un rayon certifié simple.</strong><br> Avec une borne globale (K) et une marge (m(x)), un <strong>rayon</strong> (\varepsilon^\star) certifié vérifie (m(x)&gt;2K\varepsilon^\star), d’où (\varepsilon^\star&lt;\tfrac{m(x)}{2K}).</p> </blockquote> <hr> <h2 id="2-relaxations-linéaires-bornes-par-point">2) <strong>Relaxations linéaires</strong> (bornes par point)</h2> <p>Objectif : obtenir des <strong>bornes plus serrées et spécifiques à l’exemple (x)</strong> en linéarisant les non-linéarités via leurs <strong>enveloppes convexes</strong> dépendant des bornes <strong>pré-activation</strong> ([l,u]).</p> <h3 id="exemple-pour-relu">Exemple pour ReLU</h3> <p>Pour (z=\mathrm{ReLU}(x)) avec (l\le x \le u) :</p> <ul> <li>Si (u \le 0) : (z=0).</li> <li>Si (l \ge 0) : (z=x).</li> <li>Si (l&lt;0&lt;u) (zone ambiguë), enveloppe convexe standard : [ z \ge 0,\quad z \ge x,\quad z \le \frac{u}{u-l}\,(x-l). ] Ces contraintes <strong>linéaires</strong> sont propagées couche par couche pour obtenir une <strong>relaxation convexe</strong> du réseau sur le domaine ({x+\delta:|\delta|_p\le \varepsilon}).</li> </ul> <h3 id="ibp-crown-deeppoly-idées-clés">IBP, CROWN, DeepPoly (idées clés)</h3> <ul> <li> <strong>IBP (Interval Bound Propagation)</strong> : propage des <strong>intervalles</strong> ([l,u]) (rapide, parfois lâche).</li> <li> <strong>CROWN / LiRPA</strong> : propage des <strong>bornes linéaires</strong> (majorants/minorants affines) en arrière pour serrer les bornes de <strong>sortie</strong>.</li> <li> <strong>DeepPoly</strong> : relaxation polyédrale plus fine que de simples intervalles.</li> <li> <strong>CROWN-IBP</strong> : hybride (IBP pour bornes intermédiaires + CROWN pour sorties) = <strong>compromis précision/coût</strong>, utile en <strong>entraînement certifié</strong>.</li> </ul> <h3 id="lire-un-certificat-avec-relaxations">Lire un <strong>certificat</strong> avec relaxations</h3> <p>Pour chaque logit (j), on obtient : [ \underbrace{L_j}<em>{\text{borne inf}} \;\le\; f_j(x+\delta) \;\le\; \underbrace{U_j}</em>{\text{borne sup}} \quad\text{pour toute }|\delta|<em>p\le\varepsilon. ] Si (\;L</em>{y} &gt; \max_{j\ne y} U_j\;), alors la prédiction (y) est <strong>provablement invariante</strong> aux perturbations admissibles.</p> <h3 id="entraînement-certifié">Entraînement certifié</h3> <p>On peut <strong>minimiser une borne supérieure</strong> de la <strong>perte robuste</strong> (p. ex. en remplaçant les logits par leurs bornes ((L_y,U_j)) dans la CE), ce qui <strong>augmente</strong> la robustesse certifiée sans résoudre un problème NP-difficile.</p> <hr> <h2 id="3-jacobinet--encadrer-le-gradient-lipschitz-locale">3) <strong>JacobiNet</strong> : encadrer le <strong>gradient</strong> (Lipschitz <strong>locale</strong>)</h2> <p><code class="language-plaintext highlighter-rouge">jacobinet</code> construit explicitement le <strong>réseau du backward</strong> (chaîne des dérivées) comme un modèle Keras, ce qui permet :</p> <ul> <li>de <strong>calculer/visualiser</strong> le <strong>Jacobien</strong> (J_f(x)) ou des directions/colonnes spécifiques ;</li> <li>d’estimer des <strong>normes opérateur</strong> (|J_f(x)|_{p\to q}) (i.e., une <strong>constante de Lipschitz locale</strong>) ;</li> <li>de définir des <strong>régularisations</strong> basées Jacobien (pénaliser (|J_f(x)|)) ou d’auditer la <strong>stabilité</strong> des explications par gradient.</li> </ul> <p><strong>Lien avec la robustesse locale.</strong><br> Pour (|\delta|<em>p) petit, [ |f(x+\delta)-f(x)|_q \;\approx\; |J_f(x)|</em>{p\to q}\,|\delta|_p, ] donc borner (|J_f(x)|) <strong>resserre</strong> les certificats <strong>locaux</strong> et éclaire la <strong>sensibilité</strong> instance-dépendante.</p> <h1 id="evaluation-de-la-stabilité-du-modèle">Evaluation de la stabilité du modèle</h1> <p>Une bonne explication (\phi(x,y)) doit être <strong>stable localement</strong> : de petites perturbations d’entrée qui ne changent (presque) pas la prédiction ne devraient <strong>pas</strong> faire varier fortement l’explication. La métrique <a href="https://github.com/deel-ai/xplique/blob/master/xplique/metrics/stability.py" rel="external nofollow noopener" target="_blank">AverageStability de Xplain de deel-ai</a> quantifie cette sensibilité locale : plus sa valeur est <strong>faible</strong>, plus les explications sont <strong>robustes</strong> au bruit.</p> <p>Soit un explainer (\phi:\mathbb{R}^d\times\mathcal{Y}\to\mathbb{R}^p).<br> Pour chaque échantillon ((x_i,y_i)), on calcule l’explication de base (\phi_i=\phi(x_i,y_i)).<br> On génère (K) voisins bruités : [ \varepsilon_{ik}\sim \mathcal{U}([0,r])^{d},\qquad x_{ik}=x_i+\varepsilon_{ik},\qquad k=1,\dots,K, ] puis leurs explications (\phi_{ik}=\phi(x_{ik},y_i)) (même cible que (y_i), répliquée).</p> <p>On mesure la distance moyenne entre explications bruitées et explication de base : [ \bar d_i \;=\; \frac{1}{K}\sum_{k=1}^{K} d\big(\phi_{ik},\,\phi_i\big), ] et on agrège sur (N) échantillons : [ S \;=\; \frac{1}{N}\sum_{i=1}^{N} \bar d_i. ]</p> <p>Ici (d(\cdot,\cdot)) est une métrique choisie par l’utilisateur, typiquement : [ d_{L1}(a,b)=\sum_{j=1}^{p} |a_j-b_j|,\qquad d_{L2}(a,b)=\sqrt{\sum_{j=1}^{p} (a_j-b_j)^2}. ]</p> <p>On a comme paramètres :</p> <ul> <li> <strong>Rayon (r)</strong> : contrôle l’échelle des perturbations (plus (r) est grand, plus (S) tend à croître).</li> <li> <strong>Nombre d’échantillons (K)</strong> : réduit la variance de l’estimation de (S).</li> </ul> <h1 id="evaluation-de-la-fidélité-du-modèle">Evaluation de la fidélité du modèle</h1> <h1 id="explication-de-la-prédiction-du-modèle">Explication de la prédiction du modèle</h1> <p>Il existe plusieurs approches pour expliquer la génération d’un modèle de deep learning. Chacune de ces familles et sous-familles dépendent notamment du type d’entrée (texte, image, données tabulaires, etc) et du type de modèle (convolution, transformers, etc). On illustre chacune des méthodes pour 2 types de cas d’usage: classification de textes et détection d’objets dans des images.</p> <p>A noter que le cas d’usage de classification de texte qu’on va utiliser est sur la classification de NOTAMs (notes envoyées au pilote), via un <a href="https://huggingface.co/answerdotai/ModernBERT-base" rel="external nofollow noopener" target="_blank">ModernBert</a> fine-tuné sur le jeu de données de classification de <a href="https://huggingface.co/datasets/DEEL-AI/NOTAM" rel="external nofollow noopener" target="_blank">NOTAMS</a>, et que le cas d’usage de détection d’objet dans les images qu’on va utiliser est pour la prédiction de piste d’atterrissage dans les image, avec un Yolov8 fine-tuné sur la détection de pistes d’atterrissage (LARD_train_BIRK_LFST: https://entrepot.recherche.data.gouv.fr/dataset.xhtml?persistentId=doi:10.57745/MZSH2Y). Le modèle utilisé est https://github.com/AnnabellePundaky/runway-bounding-box-detection-NEW.</p> <h2 id="explication-de-la-génération-par-carte-dattribution-de-la-donnée-dentrée-obtenue-par-calcul-de-gradient-par-rapport-à-lentrée-pour-identifier-les-zones-dintérêt-sur-linput-portées-par-le-modèle-pour-quil-effectue-sa-génération">Explication de la génération par carte d’attribution de la donnée d’entrée obtenue par calcul de gradient par rapport à l’entrée pour identifier les zones d’intérêt sur l’input portées par le modèle pour qu’il effectue sa génération</h2> <p>Les méthodes d’attribution basées sur le gradient exploitent les dérivées partielles du modèle pour quantifier l’importance de chaque élément unitaire de la donnée d’entrée dans une prédiction donnée. Le principe fondamental repose sur le calcul du gradient de la fonction de sortie par rapport aux différents éléments de la donnée d’entrée.</p> <p>Voici un exemple de résultat obtenu pour l’ensemble des méthodes décrites pour la prédiction de la classe “Landing Navaids” (prédiction correcte) par un modèle entraîné sur le jeu de données de classification de NOTAM :</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/explainable_deeplearning/gradient_based_approaches_text_classif-480.webp 480w,/assets/img/explainable_deeplearning/gradient_based_approaches_text_classif-800.webp 800w,/assets/img/explainable_deeplearning/gradient_based_approaches_text_classif-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/explainable_deeplearning/gradient_based_approaches_text_classif.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>A noter que pour appliquer les différentes fonctions présentées ici, il faut juste wrapper correctement le modèle pour qu’il soit compatible avec ce qu’attend Xplain, et avoir accès aux gradients du modèle.</p> <p>Voici un exemple pour un modèle transformers, et si on veut calculer le gradient par rapport à l’embedding (chacune de ses dimension notamment) des tokens d’entrée::</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">from</span> <span class="n">xplique.wrappers</span> <span class="kn">import</span> <span class="n">TorchWrapper</span>
<span class="kn">from</span> <span class="n">xplique.attributions</span> <span class="kn">import</span> <span class="n">Saliency</span><span class="p">,</span> <span class="n">IntegratedGradients</span><span class="p">,</span> <span class="n">GradientInput</span><span class="p">,</span> <span class="n">SmoothGrad</span><span class="p">,</span> <span class="n">VarGrad</span><span class="p">,</span> <span class="n">SquareGrad</span>

<span class="k">class</span> <span class="nc">ModernBERTEmbedsWrapper</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">base_model</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">base</span> <span class="o">=</span> <span class="n">base_model</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">"</span><span class="s">am</span><span class="sh">"</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">am</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">am</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">base</span><span class="p">(</span><span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">am</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">.</span><span class="n">logits</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">).</span><span class="nf">eval</span><span class="p">()</span>
<span class="n">wrap</span> <span class="o">=</span> <span class="nc">ModernBERTEmbedsWrapper</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">wrap</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
<span class="n">wrapped_model</span> <span class="o">=</span> <span class="nc">TorchWrapper</span><span class="p">(</span><span class="n">wrap</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div> <p>Et maintenant, on peut instancier n’importe quelle méthode d’explicabilité à base de ce wrapped_model:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">explainer</span> <span class="o">=</span> <span class="nc">Saliency</span><span class="p">(</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">operator</span><span class="o">=</span><span class="sh">"</span><span class="s">classification</span><span class="sh">"</span><span class="p">,</span> <span class="o">**</span><span class="n">params_of_the_explainer</span><span class="p">)</span> <span class="c1"># pour la détection d'objets, on peut avoir operator=xplique.Tasks.OBJECT_DETECTION. En fonction de l'approche, on a des paramètres différents (par exemple, IntegratedGradients nécessite de défininir une valeur de baseline)
</span></code></pre></div></div> <p>Puis on peut expliquer tous les inputs / outputs que l’on souhaite, en les mettant en tensor pytorch:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">liste de textes d</span><span class="sh">'</span><span class="s">entrée du modèle à tester</span><span class="sh">"</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">liste des labels</span><span class="sh">"</span><span class="p">]</span>
<span class="n">tok</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">)</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">tok</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">].</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">attention_mask</span> <span class="o">=</span> <span class="n">tok</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">].</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">emb_layer</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">get_input_embeddings</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">embeds</span> <span class="o">=</span> <span class="nf">emb_layer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">label2id</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">num_labels</span><span class="p">).</span><span class="nf">float</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
<span class="n">E</span> <span class="o">=</span> <span class="n">explainer</span><span class="p">.</span><span class="nf">explain</span><span class="p">(</span><span class="n">embeds</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">float</span><span class="p">().</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">targets</span><span class="p">).</span><span class="nf">numpy</span><span class="p">()</span>
<span class="n">token_scores</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">E</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># on fait la forme L2 des gradient par rapport à chaque dimension de l'embedding (car on a dim_model scores) par token
</span></code></pre></div></div> <h3 id="la-méthode-saliency-de-xplain-de-deel-ai">La méthode <a href="https://github.com/deel-ai/xplique/blob/master/xplique/attributions/saliency.py" rel="external nofollow noopener" target="_blank">Saliency de Xplain de deel-ai</a> </h3> <p>La méthode Saliency calcule le gradient absolu de la sortie par rapport à l’entrée du modèle (l’input):</p> \[\forall \text{dimension } i \text{ de l'entrée x (pixel, l'embedding d'un token, etc):} S_i = \left| \frac{\partial f(x)}{\partial x_i} \right|\] <p>A notée qu’ici, chaque dimension de l’entrée peut elle-même être de plusieurs dimensions (exemple d’un pixel en 3 dimensions (R,G,B), ou d’un token en dim_model dimensions). Dans ce cas, soit on prend le maximum des gradients de la prédiction du modèle par rapport à chaque dimension de l’embedding du token d’entrée ou du pixel d’entrée, soit on prend la norme L2 des gradients des dimensions (exemple du papier https://aclanthology.org/2024.emnlp-main.347.pdf), soit on prend la moyenne, …</p> <p>Dans le code https://github.com/deel-ai/xplique/blob/master/xplique/attributions/saliency.py:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Saliency</span><span class="p">(</span><span class="n">WhiteBoxExplainer</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>
                 <span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">,</span>
                 <span class="n">output_layer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
                 <span class="n">operator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Tasks</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">OperatorSignature</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
                 <span class="n">reducer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="sh">"</span><span class="s">max</span><span class="sh">"</span><span class="p">,):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">operator</span><span class="p">,</span> <span class="n">reducer</span><span class="p">)</span>

    <span class="nd">@sanitize_input_output</span> <span class="c1"># Cette fonction s'assure que les inputs et outputs du modèle sont des tf.Tensors
</span>    <span class="nd">@WhiteBoxExplainer._harmonize_channel_dimension</span>

    <span class="k">def</span> <span class="nf">explain</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="c1"># 1. Calcul du gradient via backpropagation
</span>        <span class="n">gradients</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">batch_gradient</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1"># 2. Application de la valeur absolue
</span>        <span class="n">gradients</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">gradients</span><span class="p">)</span>
        
        <span class="c1"># 3. Pour les images RGB, réduction sur les canaux (max par défaut)
</span>        <span class="c1"># Cela donne l'importance maximale parmi R, G, B pour chaque pixel
</span>        <span class="k">return</span> <span class="n">gradients</span>
</code></pre></div></div> <p>A noter que cette approche a plusieurs limites, notamment:</p> <ul> <li>La valeur absolue du gradient de la prédiction du modèle par rapport aux unités de l’input ne permet pas de distinguer les unités de l’input qui ont un impact négatifs de ceux qui ont un impact positif sur la prédiction modèle</li> <li>Quand les unités d’entrée sont de haute dimension ; pour les images, il s’agit des pixels, qui sont de faibles dimensions (R, G, B uniquement), donc “faciles” à aggréger pour obtenir un score unique de saillance par unité (pixel) d’entrée. Par contre, quand on a des unités de l’input qui sont de haute dimension, cela peut être compliqué. C’est par exemple le cas pour les modèles de langue, où l’unité d’un input est un token, plus précisément l’embedding d’un token, qui lui est de très grande dimension (en fonction du modèle). Ainsi, il est compliqué d’agréger les D (D = dim_model) gradients obtenus pour avoir un score unique par unité de l’input. On utilise couremment la norme L2 des gradients de chaque dimensions de l’embedding des tokens d’entrée pour se faire: mais ceci est discutable. <em>(on peut penser notamment à deux ou plusieurs dimensions qui sont très corrélées, alors leurs composantes de gradient pointent en général dans la même direction, et quand on fait la somme des carrés, ces contributions s’additionnent comme si c’étaient deux informations indépendantes, alors qu’elles portent le même signal, du coup la norme L2 des gradients par rapport à chaque dimension du modèle n’est pas forcément optimale)</em> </li> <li>Le gradient de la prédiction par rapport aux unités d’entrée n’a pas forcément de sens en termes absolu: un gradient petit n’implique pas forcément que l’unité de l’input n’est pas important: une unité peut être très influente mais avoir un gradient (local) faible. $\nabla_{x_i}(f(x))$ approxime l’effet de micro-perturbations de l’unité $i$ de l’input, pas le remplacement de cette unité (opération discrète et non-locale). Une unité peut être cruciale pour la classe, tout en ayant un gradient local faible. En effet, Le gradient est une pente locale. Si, autour de l’unité $i$ de l’input, la fonction “s’aplatit”, alors la pente est proche de 0, donc le gradient local est faible, même si l’unité $i$ porte une info décisive pour la prédiction.</li> </ul> <p>D’autres approches permettent de combler l’effet “local” du gradient, notamment les approches d’Integrated Gradients, ou de Gradient x Input.</p> <h3 id="la-méthode-des-gradients-intégrés-de-xplain-de-deel-ai">La méthode des <a href="https://github.com/deel-ai/xplique/blob/master/xplique/attributions/integrated_gradients.py" rel="external nofollow noopener" target="_blank">Gradients Intégrés de Xplain de deel-ai</a> </h3> <p>Les <strong>gradients intégrés (IG)</strong> attribuent à chaque caractéristique $i$ une contribution <strong>cumulative</strong> le long d’un chemin qui relie une <strong>référence (baseline)</strong> $x’$ à l’entrée $x$. En choisissant le <strong>chemin linéaire</strong> $\gamma(\alpha)=x’ + \alpha\,(x-x’)$, $\alpha \in [0,1]$, l’attribution IG pour la $i$-ème dimension est \(\boxed{\;\mathrm{IG}_i(x; x') \;=\; (x_i - x'_i)\,\int_{0}^{1} \frac{\partial F\big(\gamma(\alpha)\big)}{\partial x_i}\, d\alpha\;}\) et, en pratique, on l’approxime par une somme de Riemann avec $m$ pas : \(\mathrm{IG}_i(x; x') \;\approx\; (x_i - x'_i)\,\frac{1}{m}\sum_{k=1}^{m} \left.\frac{\partial F(z)}{\partial x_i}\right|_{z\,=\,x' + \tfrac{k}{m}(x-x')}.\) En <strong>NLP</strong>, on applique IG sur l’<strong>espace d’embedding</strong> : si $e(x)\in\mathbb{R}^{d}$ est l’entrée réelle du réseau (concaténation des embeddings par token), on interpole $e’ + \alpha\,(e-e’)$ et on dérive $F$ par rapport aux composantes d’<strong>embedding</strong> (la baseline $e’$ est souvent le vecteur nul, un token [PAD], ou un embedding « neutre »).</p> <p>IG contourne le biais <strong>local</strong> des approches de gradient pur en <strong>agrégeant</strong> l’information de gradient <strong>le long du chemin</strong> $\gamma(\alpha)$ depuis la baseline $x’$ (où la sortie est « neutre ») vers $x$. Intuitivement, même si $\nabla F(x)\approx 0$, il existe souvent des $\alpha\in(0,1)$ où $\nabla F(\gamma(\alpha))$ est <strong>grand</strong> (région non saturée) ; l’intégrale \(\int_{0}^{1} \frac{\partial F\big(x' + \alpha(x-x')\big)}{\partial x_i}\, d\alpha\) <strong>accumule</strong> ces contributions, produisant une attribution fidèle au <strong>chemin causal continu</strong> qui mène de $x’$ à $x$. IG est ainsi une version <strong>chemin-intégrée</strong> du gradient, reliée à la <strong>valeur d’Aumann–Shapley</strong> (analogue continu des valeurs de Shapley), et hérite d’une interprétation en termes de <strong>coût marginal moyen</strong> le long de l’activation du feature $i$.</p> <p>A noter que le choix de la baseline $x’$ est majeur: il doit représenter une <strong>entrée de référence</strong> « absence d’information » (image noire, bruit faible, embedding nul/[\mathrm{PAD}], etc.). Le résultat dépend de ce choix, mais la <strong>complétude</strong> garantit $\sum_i \mathrm{IG}_i = F(x)-F(x’)$.</p> <p>Exemple d’application:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">xplique.attributions</span> <span class="kn">import</span> <span class="n">IntegratedGradients</span>

<span class="n">explainer</span> <span class="o">=</span> <span class="nc">IntegratedGradients</span><span class="p">(</span>
    <span class="n">wrapped_model</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="c1"># Nombre de points d'interpolation
</span>    <span class="n">baseline_value</span><span class="o">=</span><span class="mf">0.0</span> <span class="c1"># Valeur de référence pour la baseline
</span><span class="p">)</span>
<span class="n">attributions</span> <span class="o">=</span> <span class="nf">explainer</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
</code></pre></div></div> <p>Attention en revanche: Dans la librairie Xplique, on approxime l’intégrale continue $I_i=\int_0^1 g_i(\alpha)\,d\alpha$ — i.e. la moyenne du gradient $g_i(\alpha)=\frac{\partial F(x’+\alpha(x-x’))}{\partial x_i}$ le long du chemin $\gamma(\alpha)=x’+\alpha(x-x’)$ avec la règle du trapèze. Comme on ne dispose pas d’une primitive explicite pour un réseau de neurones, on discrétise l’intégrale en une somme finie sur $m$ points. Plusieurs schémas sont possibles :</p> <ul> <li> <strong>Riemann (rectangle)</strong> : $I_i \approx \frac{1}{m}\sum_{k=1}^{m} g_i!\big(\tfrac{k}{m}\big)$ (erreur $O(1/m)$) ;</li> <li> <strong>Milieu (midpoint)</strong> : $I_i \approx \frac{1}{m}\sum_{k=1}^{m} g_i!\big(\tfrac{k-\tfrac12}{m}\big)$ (erreur $O(1/m^2)$) ;</li> <li> <strong>Trapèze (composite)</strong> : $I_i \approx \frac{1}{m}!\Big[\tfrac12 g_i(0)+\sum_{k=1}^{m-1} g_i!\big(\tfrac{k}{m}\big)+\tfrac12 g_i(1)\Big]$ (erreur $O(1/m^2)$, plus précis et plus symétrique) ;</li> </ul> <p>La librairie Xplique utilise la règle du trapèze, qui offre une meilleure précision (et respecte mieux la propriété de complétude $\sum_i \mathrm{IG}_i \approx F(x)-F(x’)$) à coût identique.</p> <p>A noter que la valeur de référence pour la baseline est majeure: par exemple, on peut prendre le token de padding pour le texte.</p> <h3 id="la-méthode-gradient-x-input-de-xplain-de-deel-ai">La méthode <a href="https://github.com/deel-ai/xplique/blob/master/xplique/attributions/gradient_input.py" rel="external nofollow noopener" target="_blank">gradient x input de Xplain de deel-ai</a> </h3> <p>Gradient × Input attribue l’importance d’une caractéristique $x_i$ comme le produit élément-par-élément entre sa sensibilité locale et sa présence effective : \(\mathbf{A}(x)\;=\;x\;\odot\;\nabla_x g(f,x,y),\quad\text{soit}\quad A_i(x)=x_i\,\frac{\partial g(f,x,y)}{\partial x_i}.\) Le gradient seul $\partial g/\partial x_i$ mesure “à quel point” la sortie changerait si l’on bougeait $x_i$, mais ne tient pas compte de combien de cette caractéristique est présente dans l’entrée ; en le pondérant par $x_i$, on obtient une contribution sensibilité × magnitude. Dans un modèle linéaire $g(x)=w^\top x$, on a $\nabla_x g = w$ et donc $A_i = x_i w_i$, ce qui correspond exactement à la part de $x_i$ dans la sortie. Plus généralement, c’est la décomposition de Taylor d’ordre 1 autour de 0 : $g(x)\approx g(0)+\sum_i x_i\,\partial g/\partial x_i$, d’où une attribution locale et signée. En pratique (y compris dans Xplique), on calcule le gradient d’entrée du scalaire choisi (p. ex. logit de classe via un <em>operator</em>) puis on le multiplie élément-par-élément par $x$ pour produire la carte d’attributions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">GradientInput</span><span class="p">(</span><span class="n">WhiteBoxExplainer</span><span class="p">):</span>
    <span class="nd">@sanitize_input_output</span>
    <span class="nd">@WhiteBoxExplainer._harmonize_channel_dimension</span>
    <span class="k">def</span> <span class="nf">explain</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>
                <span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">],</span>
                <span class="n">targets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">batch_gradient</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">gradients_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">multiply</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gradients_inputs</span>
</code></pre></div></div> <h3 id="la-méthode-smoothgrad-de-xplain-de-deel-ai">La méthode <a href="https://github.com/deel-ai/xplique/blob/master/xplique/attributions/gradient_statistics/smoothgrad.py" rel="external nofollow noopener" target="_blank">SmoothGrad de Xplain de deel-ai</a> </h3> <p>Les cartes de saillance basées sur le gradient pur $\nabla_x g(f,x,y)$ sont souvent granulaires : de très petites variations d’entrée (ou du point d’évaluation dans les activations) peuvent faire fluctuer fortement le gradient à cause des non-linéarités locales (ReLU, max-pool, normalisations) ou des changements de région affine notamment. Résultat : des pixels/tokens isolés “s’allument” ou “s’éteignent” sans cohérence spatiale/sémantique. Visuellement, ça donne du bruit.</p> <p>Plutôt que de se fier au gradient en un point unique $x$, SmoothGrad moyenne les gradients dans un petit voisinage gaussien de $x$. Cette moyenne annule statistiquement les fluctuations idiosyncratiques (le « bruit ») et renforce les tendances stables (structure commune dans le voisinage).</p> <p>Soit $h(x) \equiv g(f,x,y)$ un scalaire (ex. logit de la classe $y$). On introduit un bruit additif \(\delta \sim \mathcal N(0,\sigma^2 I),\) où $\delta$ est un tenseur de même forme que $x$, dont chaque composante est tirée d’une loi normale centrée d’écart-type $\sigma$. On définit : \(\phi_{\mathrm{SG}}(x) \;=\; \mathbb E_{\delta}\big[\nabla_x h(x+\delta)\big] \;\approx\; \frac{1}{N}\sum_{i=1}^N \nabla_x h\!\big(x+\delta_i\big), \quad \delta_i \stackrel{\text{i.i.d.}}{\sim} \mathcal N(0,\sigma^2 I).\)</p> <ul> <li>$\sigma$ (<em>noise</em>) règle la taille du voisinage ; on le choisit relatif à l’échelle des entrées (p.ex. $\sigma\approx 0{,}2$ si $x\in[0,1]$).</li> <li>$N$ (<em>nb_samples</em>) contrôle la variance Monte-Carlo de l’estimateur ($\propto 1/\sqrt{N}$) et le coût (il faut $N$ gradients).</li> </ul> <p>Pour plus de précision sur la façon dont cela est codé:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">GradientStatistic</span><span class="p">(</span><span class="n">WhiteBoxExplainer</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>
                 <span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">,</span>
                 <span class="n">output_layer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
                 <span class="n">operator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Tasks</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">OperatorSignature</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
                 <span class="n">reducer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="sh">"</span><span class="s">mean</span><span class="sh">"</span><span class="p">,</span>
                 <span class="n">nb_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
                 <span class="n">noise</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">operator</span><span class="p">,</span> <span class="n">reducer</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">nb_samples</span> <span class="o">=</span> <span class="n">nb_samples</span>
        <span class="n">self</span><span class="p">.</span><span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span>

    <span class="nd">@sanitize_input_output</span>
    <span class="nd">@WhiteBoxExplainer._harmonize_channel_dimension</span>
    <span class="k">def</span> <span class="nf">explain</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>
                <span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">],</span>
                <span class="n">targets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="ow">or</span> <span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">nb_samples</span><span class="p">)</span>
        <span class="n">perturbation_batch_size</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">nb_samples</span><span class="p">)</span>
        <span class="n">inputs_batch_size</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="n">perturbation_batch_size</span><span class="p">)</span>

        <span class="n">smoothed_gradients</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># loop over inputs (by batch if batch_size &gt; nb_samples, one by one otherwise)
</span>        <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="nf">batch_tensor</span><span class="p">((</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">),</span> <span class="n">inputs_batch_size</span><span class="p">):</span>
            <span class="n">total_perturbed_samples</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># reset online statistic values
</span>            <span class="n">self</span><span class="p">.</span><span class="nf">_initialize_online_statistic</span><span class="p">()</span>

            <span class="c1"># loop over perturbation (a single pass if batch_size &gt; nb_samples, batched otherwise)
</span>            <span class="k">while</span> <span class="n">total_perturbed_samples</span> <span class="o">&lt;</span> <span class="n">self</span><span class="p">.</span><span class="n">nb_samples</span><span class="p">:</span>
                <span class="n">nb_perturbations</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">perturbation_batch_size</span><span class="p">,</span>
                                       <span class="n">self</span><span class="p">.</span><span class="n">nb_samples</span> <span class="o">-</span> <span class="n">total_perturbed_samples</span><span class="p">)</span>
                <span class="n">total_perturbed_samples</span> <span class="o">+=</span> <span class="n">nb_perturbations</span>

                <span class="c1"># add noise to inputs
</span>                <span class="n">perturbed_x_batch</span> <span class="o">=</span> <span class="n">GradientStatistic</span><span class="p">.</span><span class="nf">_perturb_samples</span><span class="p">(</span>
                    <span class="n">x_batch</span><span class="p">,</span> <span class="n">nb_perturbations</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">noise</span><span class="p">)</span>
                <span class="n">repeated_targets</span> <span class="o">=</span> <span class="nf">repeat_labels</span><span class="p">(</span><span class="n">y_batch</span><span class="p">,</span> <span class="n">nb_perturbations</span><span class="p">)</span>

                <span class="c1"># compute the gradient of each noisy samples generated
</span>                <span class="n">gradients</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">batch_gradient</span><span class="p">(</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">,</span> <span class="n">perturbed_x_batch</span><span class="p">,</span> <span class="n">repeated_targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

                <span class="c1"># group by inputs and compute the average gradient
</span>                <span class="n">gradients</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span>
                    <span class="n">gradients</span><span class="p">,</span> <span class="p">(</span><span class="n">x_batch</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nb_perturbations</span><span class="p">,</span> <span class="o">*</span><span class="n">gradients</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>

                <span class="c1"># update online estimation
</span>                <span class="n">self</span><span class="p">.</span><span class="nf">_update_online_statistic</span><span class="p">(</span><span class="n">gradients</span><span class="p">)</span>

            <span class="c1"># extract online estimation
</span>            <span class="n">reduced_gradients</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_online_statistic_final_value</span><span class="p">()</span> <span class="c1"># pour SmoothGrad, cette fonction retourne la moyenne, pour VarGrad la variance, etc.
</span>            <span class="n">smoothed_gradients</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">reduced_gradients</span><span class="p">)</span>

        <span class="n">smoothed_gradients</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">smoothed_gradients</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">smoothed_gradients</span>

    <span class="nd">@staticmethod</span>
    <span class="nd">@tf.function</span>
    <span class="k">def</span> <span class="nf">_perturb_samples</span><span class="p">(</span><span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
                         <span class="n">nb_perturbations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                         <span class="n">noise</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">perturbed_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="n">nb_perturbations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">perturbed_inputs</span> <span class="o">+=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">perturbed_inputs</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">perturbed_inputs</span>
</code></pre></div></div> <h3 id="la-méthode-vargrad-de-xplain-de-deel-ai">La méthode <a href="https://github.com/deel-ai/xplique/blob/master/xplique/attributions/gradient_statistics/vargrad.py" rel="external nofollow noopener" target="_blank">VarGrad de Xplain de deel-ai</a> </h3> <p>Alors que SmoothGrad estime la moyenne des gradients sous bruit, VarGrad estime quant à lui la variance de ces mêmes gradients. Il mesure à quel point le gradient fluctue quand on perturbe légèrement l’entrée. Si le gradient est cohérent/stable dans le voisinage (même signe, même amplitude), SmoothGrad peut être fort alors que VarGrad sera faible. S’il change beaucoup (amplitude/signe) selon les perturbations, VarGrad sera élevé et mettra en avant des zones instables/fragiles.</p> <h3 id="la-méthode-squaregrad-de-xplain-de-deel-ai">La méthode <a href="https://github.com/deel-ai/xplique/blob/master/xplique/attributions/gradient_statistics/square_grad.py" rel="external nofollow noopener" target="_blank">SquareGrad de Xplain de deel-ai</a> </h3> <p>SquareGrad est la somme de ce que captent SmoothGrad (moyenne) et VarGrad (variance). Il met en avant l’intensité totale de la sensibilité locale, indépendamment du signe du gradient.</p> <h2 id="explication-de-la-génération-par-carte-dattribution-de-la-donnée-dentrée-obtenu-par-approches-de-substitution-de-certaines-parties-de-lentrée-pour-identifier-les-zones-dintérêt-sur-linput-portées-par-le-modèle-pour-quil-effectue-sa-génération">Explication de la génération par carte d’attribution de la donnée d’entrée obtenu par approches de substitution de certaines parties de l’entrée pour identifier les zones d’intérêt sur l’input portées par le modèle pour qu’il effectue sa génération</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/explainable_deeplearning/patch_based_approaches_text_classification-480.webp 480w,/assets/img/explainable_deeplearning/patch_based_approaches_text_classification-800.webp 800w,/assets/img/explainable_deeplearning/patch_based_approaches_text_classification-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/explainable_deeplearning/patch_based_approaches_text_classification.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="lapproche-docclusion">L’approche d’Occlusion</h3> <p>Cette approche consiste à faire glisser un patch de masquage sur l’entrée et, à chaque position, on remplace localement les valeurs par une constante (par exemple 0), puis on mesure la baisse du score de la classe cible par rapport au score de base sans masque. En gros, on calcule une différence de score pour la région avec et sans ce masque. Plus la baisse est grande quand une région est masquée, plus cette région est jugée importante. L’attribution finale est obtenue en représentant la baisse de score sur toutes les positions couvertes par le patch et en additionnant sur tous les patchs qui recouvrent chaque position. On produit ainsi une carte de saillance de même taille spatiale que l’entrée.</p> <p>Formule compacte : si $s_0=g(f,x,y)$ est le score de base et $s_p=g!\big(f,(1-m_p)\odot x+m_p\odot v, y\big)$ le score avec le patch $m_p$, alors l’attribution en $i$ est \(\Phi(x)_i=\sum_{p:\, i\in \mathrm{supp}(m_p)} \big(s_0 - s_p\big).\)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Préparation
</span><span class="n">masks</span> <span class="o">=</span> <span class="nf">all_sliding_window_masks</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">patch_size</span><span class="p">,</span> <span class="n">patch_stride</span><span class="p">)</span>
<span class="n">s0</span> <span class="o">=</span> <span class="nf">g</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># score de base, sans masquage: f est le modèle, x est l'entrée, y est la prédiction du modèle
</span>
<span class="n">phi</span> <span class="o">=</span> <span class="nf">zeros_like_spatial</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># carte d’attribution
</span>
<span class="k">for</span> <span class="n">batch_masks</span> <span class="ow">in</span> <span class="nf">batch</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="c1"># Appliquer les masques (broadcast sur canaux si image)
</span>    <span class="n">X_occ</span> <span class="o">=</span> <span class="nf">apply_masks</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_masks</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

    <span class="c1"># Répéter y pour matcher le batch de masques
</span>    <span class="n">Y_rep</span> <span class="o">=</span> <span class="nf">repeat</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">batch_masks</span><span class="p">))</span>

    <span class="c1"># Scores occlus
</span>    <span class="n">s_occ</span> <span class="o">=</span> <span class="nf">g</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">X_occ</span><span class="p">,</span> <span class="n">Y_rep</span><span class="p">)</span>  <span class="c1"># shape: [len(batch_masks)]
</span>
    <span class="c1"># Variations de score
</span>    <span class="n">delta</span> <span class="o">=</span> <span class="n">s0</span> <span class="o">-</span> <span class="n">s_occ</span>  <span class="c1"># shape: [len(batch_masks)]
</span>
    <span class="c1"># Peindre et sommer sur la dimension « patch »
</span>    <span class="n">phi</span> <span class="o">+=</span> <span class="nf">sum_over_patches</span><span class="p">(</span><span class="n">delta</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">...]</span> <span class="o">*</span> <span class="n">batch_masks</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="sh">"</span><span class="s">patch</span><span class="sh">"</span><span class="p">)</span>

<span class="k">return</span> <span class="n">phi</span>
</code></pre></div></div> <p>Cependant, l’occlusion est coûteuse: pour chaque région (définie par patch_size / stride), on doit réaliser une inférence sur l’image masquée et comparer au score de l’image originale (calculé une seule fois). Le nombre d’inférences croît donc linéairement avec le nombre de patches balayés, et la résolution de la carte dépend directement de la taille du patch (patchs gros donne une carte grossière ; patchs petits donne un coût élevé).</p> <h3 id="lapproche-rise">L’approche Rise</h3> <p>C’est pourquoi RISE remplace le balayage exhaustif par un échantillonnage Monte-Carlo de masques aléatoires. Rise estime une espérance conditionnelle via échantillonnage aléatoire de masques qui préservent/éteignent des régions, puis moyenne les masques pondérés par le score du modèle.</p> <h2 id="explication-de-la-génération-du-modèle-par-attribution-de-sa-génération-aux-données-dentraînements-quil-a-vu-qui-ont-positivement-ou-négativement-influencées-sa-prédiction">Explication de la génération du modèle par attribution de sa génération aux données d’entraînements qu’il a vu qui ont positivement ou négativement influencées sa prédiction</h2> <p>Les fonctions d’influence permettent d’approximer le Leave-one-out, c’est à dire cherche à estimer l’<mark>impact qu'aurait un exemple d'entraînement sur la perte d'un exemple de test (ou sur plusieurs résultats du modèle sur un jeu de données test)</mark>.</p> \[\begin{split} \mathrm{Influence}\bigl(z_{\mathrm{train}}\to z_{\mathrm{test}}\bigr) &amp;= \frac{d}{d\varepsilon}\, \mathcal{L}\bigl(z_{\rm test},\,\theta_\varepsilon(z_\text{train})\bigr)\Big|_{\varepsilon=0} \\ &amp;\approx -\nabla_\theta \,\mathcal{L}\bigl(z_{\mathrm{test}},\,\hat{\theta} \bigr)\,H_\theta^{-1}(\hat{\theta})\,\nabla_\theta \mathcal{L}(z_{\rm train},\hat{\theta}) \\ &amp;\approx -\nabla_\theta \,\mathcal{L}\bigl(z_{\mathrm{test}},\,\hat{\theta} \bigr)\,(G_\theta(\hat{\theta}) + \lambda I)^{-1}\,\nabla_\theta \mathcal{L}(z_{\rm train},\hat{\theta}) \end{split}\] <p>Où:</p> <ul> <li>\(\hat{\theta}\) sont les poids du modèle préentraîné (poids supposés optimiaux pour le jeu de pretraining du LLM)</li> <li>\(\theta_\varepsilon(z_\text{train})\) sont les poids du modèle “modifié”, ie lorsqu’on upweight de $\varepsilon$ l’exemple d’entraînement $z_\text{train}$</li> <li>\(\theta\) est une variable muette (eg pour le gradient, on dérive par rapport aux paramètres du modèle et on applique en un point)</li> <li>Tous les $\theta$ sont des vecteurs colonne des poids du modèle</li> <li>$\mathcal{L}$ est la loss du modèle, donc ici, vu qu’on est dans le cas des LLMs, c’est la cross-entropy loss (negative log-likelihood), ie pour une séquence de taille $T$ ($x_1$, $x_2$, …, $x_T$): \(\mathcal{L} = -\frac{1}{T}\sum_{t=1}^{T} \log P(x_t \mid x_1, x_2, \ldots, x_{t-1})\)</li> <li>$f$ est une fonction (moyenne, ou autre) sur plusieurs résultats du modèle sur un jeu de données test noté $x$. Il nous permet de ne pas évaluer l’impact de l’upweight d’un $z_\text{train}$ sur la loss d’un $z_\text{test}$, mais sur un ensemble de type de données $x$ (car parfois, on ne veut pas calculer l’influence d’une donnée d’entraînement sur la loss d’un prompt, mais sur la performance (pas forcément la loss d’ailleurs) sur un certain type de prompt)</li> <li>$H_\theta$ est la hessienne (dérivée seconde par rapport aux paramètres du modèle)</li> <li>$G_\theta$ est la Hessienne de Gauss-Newton qu’on va voir plus loin dans ce post, qui est en fait une approximation de la hessienne</li> <li>$\lambda$ est un terme dit de “damping”, dû au fait que la loss n’est pas convexe, qu’on verra plus loin dans le post</li> </ul> <p>Plus précisément, avec les foncitons d’influence, on cherche à estimer l’<strong>impact de l”up-weight” de la loss sur $z_\text{train}$ sur qqch, ie on se pose la question: “<mark>si je donnais un peu plus de poids à ce terme de loss dans l’objectif global, comment cela ferait-il bouger mes paramètres et, avec ces nouveaux paramètres, comment ça modifierait ma performance sur un point de test, ou sur une fonction?</mark>“</strong>. A noter que <mark>$f_{\theta_\varepsilon(z_\text{train})}(x)$ peut être n'importe quelle fonction (par exemple ça peut être la moyenne des prédictions sur un ensemble de données types $x$</mark> (cf le papier <a href="https://arxiv.org/pdf/2505.19949" rel="external nofollow noopener" target="_blank">Which Data Attributes Stimulate Math and Code Reasoning? An Investigation via Influence Functions</a> qui cherche à calculer l’influence des textes d’entraînement sur la génération de code (moyenne de des log probabilité de la génération de chaque token de code générés dans un benchmark sachant un problème de code en langage naturel à résoudre)), la différence entre 2 prédictions du modèle, …)</p> <h2 id="explication-de-la-génération-du-modèle-par-la-façon-dont-le-modèle-couche-par-couche-neurone-par-neurone-etc-a-traité-lentrée-pour-effectuer-sa-prédiction-quels-concepts-intermédiaires-a-t-il-représenté-etc">Explication de la génération du modèle par la façon dont le modèle (couche par couche, neurone par neurone, etc) a traité l’entrée pour effectuer sa prédiction (quels concepts intermédiaires a-t-il représenté, etc)</h2> <p>Une des librairies qui explique les concepts d’un modèle de vision est <a href="https://github.com/deel-ai/Craft" rel="external nofollow noopener" target="_blank">Craft de Deel-AI</a> TODO</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'camillebrl/camillebrl.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Camille Barboule. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/lightbox2@2.11.5/dist/js/lightbox.min.js" integrity="sha256-A6jI5V9s1JznkWwsBaRK8kSeXLgIqQfxfnvdDOZEURY=" crossorigin="anonymous"></script> <script defer src="/assets/js/photoswipe-setup.js" type="module"></script> <script defer src="https://cdn.jsdelivr.net/npm/spotlight.js@0.7.8/dist/spotlight.bundle.min.js" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/venobox@2.1.8/dist/venobox.min.js" integrity="sha256-LsGXHsHMMmTcz3KqTaWvLv6ome+7pRiic2LPnzTfiSo=" crossorigin="anonymous"></script> <script defer src="/assets/js/venobox-setup.js?897c1d9c0b6fcf82b949511c1609d055" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> <script>
      document.addEventListener('DOMContentLoaded', function() {
        // Fonction pour créer un ID à partir du texte (compatible avec Jekyll slugify)
        function createId(text) {
          return text.trim()
            .toLowerCase()
            .normalize('NFD').replace(/[\u0300-\u036f]/g, '') // Enlever les accents
            .replace(/[^\w\s-]/g, '') // Enlever les caractères spéciaux
            .replace(/\s+/g, '-') // Remplacer les espaces par des tirets
            .replace(/-+/g, '-') // Éviter les tirets multiples
            .replace(/^-|-$/g, ''); // Enlever les tirets au début et à la fin
        }
        
        // Fonction pour décoder et normaliser une ancre d'URL
        function normalizeAnchor(anchor) {
          try {
            // Décoder l'URL
            const decoded = decodeURIComponent(anchor);
            // Appliquer la même normalisation que createId
            return createId(decoded);
          } catch (e) {
            return anchor;
          }
        }
        
        // Récupérer tous les headers dans l'article
        const article = document.querySelector('d-article');
        const headers = article.querySelectorAll('h1, h2, h3, h4, h5, h6');
        const tocContainer = document.getElementById('toc-container');
        
        if (headers.length === 0) return;
        
        // Filtrer les headers pour exclure ceux dans d-contents et d-title
        const filteredHeaders = Array.from(headers).filter(header => {
          return !header.closest('d-contents') && !header.closest('d-title');
        });
        
        if (filteredHeaders.length === 0) return;
        
        // Structure pour construire la hiérarchie
        let currentList = document.createElement('ul');
        tocContainer.appendChild(currentList);
        
        let stack = [{level: 0, list: currentList}];
        
        filteredHeaders.forEach((header) => {
          // Ajouter un ID au header s'il n'en a pas
          if (!header.id) {
            header.id = createId(header.textContent);
          }
          
          // Déterminer le niveau (h1=1, h2=2, etc.)
          const level = parseInt(header.tagName.substring(1));
          
          // Gérer la hiérarchie
          while (stack.length > 1 && stack[stack.length - 1].level >= level) {
            stack.pop();
          }
          
          // Si on descend dans la hiérarchie
          if (stack[stack.length - 1].level < level) {
            const newList = document.createElement('ul');
            const lastItem = stack[stack.length - 1].list.lastElementChild;
            if (lastItem) {
              lastItem.appendChild(newList);
            } else {
              stack[stack.length - 1].list.appendChild(newList);
            }
            stack.push({level: level, list: newList});
          }
          
          // Créer l'élément de liste
          const listItem = document.createElement('li');
          const link = document.createElement('a');
          link.href = '#' + header.id;
          link.textContent = header.textContent;
          link.addEventListener('click', function(e) {
            e.preventDefault();
            header.scrollIntoView({ behavior: 'smooth', block: 'start' });
          });
          
          listItem.appendChild(link);
          stack[stack.length - 1].list.appendChild(listItem);
        });
        
        // Nettoyer les listes vides
        const emptyLists = tocContainer.querySelectorAll('ul:empty');
        emptyLists.forEach(list => list.remove());
        
        // Gérer la navigation depuis l'URL
        function navigateToHash() {
          if (window.location.hash) {
            const hash = window.location.hash.substring(1);
            const normalizedHash = normalizeAnchor(hash);
            
            // Essayer de trouver l'élément par ID normalisé
            let targetElement = document.getElementById(normalizedHash);
            
            // Si pas trouvé, essayer avec le hash original
            if (!targetElement) {
              targetElement = document.getElementById(hash);
            }
            
            // Si toujours pas trouvé, chercher dans tous les headers
            if (!targetElement) {
              filteredHeaders.forEach(header => {
                if (createId(header.textContent) === normalizedHash) {
                  targetElement = header;
                }
              });
            }
            
            if (targetElement) {
              setTimeout(() => {
                targetElement.scrollIntoView({ behavior: 'smooth', block: 'start' });
              }, 100);
            }
          }
        }
        
        // Naviguer au chargement de la page
        navigateToHash();
        
        // Écouter les changements de hash
        window.addEventListener('hashchange', navigateToHash);
      });
    </script> </body> </html>