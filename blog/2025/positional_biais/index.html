<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Biais Positionnels dans les transformers auto-régressifs | Camille Barboule </title> <meta name="author" content="Camille Barboule"> <meta name="description" content="Description du biais positionnel dans les transformers auto-régressifs"> <meta name="keywords" content="NLP, IR, Agents, Deep-Learning, XAI"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%9A&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://camillebrl.github.io/blog/2025/positional_biais/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightbox2@2.11.5/dist/css/lightbox.min.css" integrity="sha256-uypRbsAiJcFInM/ndyI/JHpzNe6DtUNXaWEUWEPfMGo=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@5.4.4/dist/photoswipe.min.css" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/spotlight.js@0.7.8/dist/css/spotlight.min.css" integrity="sha256-Dsvkx8BU8ntk9Iv+4sCkgHRynYSQQFP6gJfBN5STFLY=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/venobox@2.1.8/dist/venobox.min.css" integrity="sha256-ohJEB0/WsBOdBD+gQO/MGfyJSbTUI8OOLbQGdkxD6Cg=" crossorigin="anonymous"> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <style>.toc-list{list-style:none;padding-left:0}.toc-list ul{list-style:none;padding-left:1.5em}.toc-list li{margin:.5em 0}.toc-list a{text-decoration:none;color:inherit}.toc-list a:hover{text-decoration:underline}d-article>*:first-child{margin-top:0!important}d-contents+h1,d-contents+h2,d-contents+h3,d-contents+h4,d-contents+h5,d-contents+h6,d-contents+p{margin-top:2rem!important}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Biais Positionnels dans les transformers auto-régressifs",
            "description": "Description du biais positionnel dans les transformers auto-régressifs",
            "published": "June 16, 2025",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Camille</span> Barboule </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Biais Positionnels dans les transformers auto-régressifs</h1> <p>Description du biais positionnel dans les transformers auto-régressifs</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div id="toc-container" class="toc-list"> </div> </nav> </d-contents> <h1 id="introduction-sur-le-biais-positionnel">Introduction sur le biais positionnel</h1> <h2 id="le-biais-positionnel--cest-quoi-">Le biais positionnel : c’est quoi ?</h2> <div class="row"> <div class="col-md-8"> Le papier [Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/pdf/2307.03172) décrit comment, pour des contextes très longs, les LLMs se concentrent surtout sur les débuts et la fin du prompt. Le biais positionnel dans les LLMs, c'est la tendance du modèle à se concentrer excessivement sur certaines parties de l'entrée, qu'importe la sémantique. Et cette concentration influence significativement les performances et la fiabilité des transformers: en fonction de l'ordre des éléments dans le prompt, le modèle va générer des réponses différentes. Notamment, plus on a un contexte long, plus le modèle a tendance à se concentrer sur les éléments au début et à la fin du prompt (effet "lost in the middle"). </div> <div class="col-md-4"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/u-shape.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/u-shape.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="le-biais-positionnel--ça-vient-doù-">Le biais positionnel : ça vient d’où ?</h2> <ul> <li> <strong>Le masque causal</strong> <blockquote> <p>Avec un masque causal, chaque token ne peut voir que les tokens qui le précèdent. Cela signifie que les tokens situés au début sont accessibles à presque tous les calculs d’attention ultérieurs, alors que ceux situés plus tard ne le sont qu’à partir d’un certain point.</p> </blockquote> </li> <li> <strong>L’encodage de position</strong> (relatif, RoPE…) <blockquote> <p>Ce type d’encodage de position favorisent la proximité avec le token courant. Ainsi, les jetons situés près de la fin de la séquence bénéficient d’une attention renforcée, car leur représentation est plus fortement influencée par la similarité de position avec le token en cours de génération.</p> </blockquote> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/relative_pos_encoding-480.webp 480w,/assets/img/positional_biais/relative_pos_encoding-800.webp 800w,/assets/img/positional_biais/relative_pos_encoding-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/positional_biais/relative_pos_encoding.png" class="img-fluid rounded z-depth-1 float-right ml-3" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="quest-ce-que-lencodage-de-position-">Qu’est-ce que l’encodage de position ?</h2> <blockquote> <p>L’encodage de position est nécessaire dans les transformers à cause du calcul de l’attention qui prend en compte tous les azutres tokens de la séquence. Sans encodage positionnel, chaque token identique aurait la même influence, peu importe l’endroit dans la séquence :<br> “Le chat mange la souris” et “La souris mange le chat” seraient équivalents. Avec l’encodage de position, deux tokens identiques mais à des positions différentes auront des vecteurs différents.</p> </blockquote> <ol> <li> <p><strong>Encodage absolu</strong> (sinusoïdal ou appris)<br> Ajouté aux embeddings initiaux. Limité pour extrapoler à des longueurs supérieures à celles vues à l’entraînement.</p> </li> <li> <strong>Encodages relatifs</strong> <ul> <li>T5 : biais appris pour chaque distance relative.</li> <li>Alibi : biais fonctionnel selon la distance.</li> </ul> </li> <li> <strong>RoPE</strong> (Rotary Positional Encoding)<br> rotation appliqué à la représentation intermédiaire de chaque token dépendante de la position du token au niveau du calcul du score d’attention (chaque paire de dimensions du vecteur est tournée dans le plan d’un angle qui dépend de sa position dans la séquence). Mais du coup, quand on applique cette rotation à query et key, et qu’on fait un produit scalaire, le dot product dépend de la position relative $i−j$, même si on encode chaque position de manière absolue.</li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/periodic_attn.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/periodic_attn.PNG" class="rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h1 id="sota-des-approches-pour-corriger-le-biais-positionnel">SOTA des approches pour corriger le biais positionnel</h1> <h2 id="1-modifier-le-mécanisme-dattention">1. Modifier le mécanisme d’attention</h2> <ul> <li> <p><strong>Stable Mask</strong> (<a href="https://arxiv.org/pdf/2402.04779" rel="external nofollow noopener" target="_blank">2402.04779</a>)<br> Ajout d’un “pseudo-score” $-\gamma\times(j-1)$ présente une approche de “compensation” du score d’attention excessif sur les premiers tokens en ajoutant un “pseudo-score”: $-\gamma \times (j-1)$ pour la j-ième position, qui diminue au fur et à mesure de la séquence.</p> </li> <li> <p><strong>Calibration du score d’attention</strong> (<a href="https://arxiv.org/pdf/2406.16008" rel="external nofollow noopener" target="_blank">2406.16008</a>) présente une approche dans laquelle on a le score d’attention de la query avec un doc à la position k qui est fonction ($f$) de la pertinence du doc \(\text{rel}(\text{doc}_k)\) et du biais positionnel à la position k $b_k$. En simplifiant la fonction $f$ (rasoir d’Occam) par une fonction linéaire, on a alors \(\text{Attn}(\text{query}, doc_k) = \text{rel}(\text{doc}_k) + b_k + \epsilon\) <strong>Donc en gros ils supposent que le score d’attention entre le document et la query est une combinaison linéaire du biais de position et de la pertinence réelle du document avec la query</strong>. Pour isoler $\text{rel}(\text{doc}_k)$, ils <strong>introduisent un document “dummy” à la même position $k$ que le document</strong>: \(\text{doc}_{\text{k;dum}}$, on a alors $\text{rel}(\text{doc}_k) = \text{Attn}(\text{query}, doc_k) - \text{Attn}(\text{query}, doc_{k;dum}) + \epsilon\) Grâce à la pertinence “effective” de chaque document, ils calculent, $\forall k$, un coefficient de rééchelonnement $\alpha_k$, qui est une fonction Softmax appliquée sur le score de pertinence du document $\text{doc}_k$.</p> </li> <li> <p><strong>Attention bidirectionnelle entre documents</strong> (PCW <a href="https://arxiv.org/pdf/2212.10947" rel="external nofollow noopener" target="_blank">2212.10947</a>) propose une modification de l’attention entre documents pour un traitement “indépendant”: Au lieu d’utiliser l’attention causale (unidirectionnelle) qui impose un ordre strict. A contrario, le papier <a href="https://openreview.net/attachment?id=fvkElsJOsN&amp;name=pdf" rel="external nofollow noopener" target="_blank">l’approche d’attention bidirectionnelle entre documents</a> propose une approche d’attention bidirectionnelle qui permet à chaque document d’interagir équitablement avec tous les autres.</p> <div class="row"> <div class="col-md-6"> </div> </div> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/bidirectional_attn.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/bidirectional_attn.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;/div&gt;
&lt;div class="col-md-6"&gt;
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/cropped_attn.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/cropped_attn.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;/div&gt;
</code></pre></div></div> <p>&lt;/div&gt;</p> <ul> <li> <p><strong>Diminuer le biais positionnel dû à RoPE</strong>: L’objectif principal de <a href="https://arxiv.org/pdf/2104.09864" rel="external nofollow noopener" target="_blank">ROPE</a> est d’encoder l’information positionnelle de sorte que le produit scalaire des embeddings de requête et de clé contienne intrinsèquement l’information relative à la position, c’est-à-dire $f(q_m, m)^T f(k_n, n) = f(q_m, k_n, m - n)$. Ici, $f$ est la fonction d’encodage positionnel appliquée aux embeddings de requête et de clé aux positions $m$ et $n$, respectivement. Pour satisfaire cette condition, la fonction $f$ est définie comme une fonction complexe vectorielle :</p> \[f(x, m) = x e^{im\theta} = \left[(x_1 + i x_2)e^{im\theta_1};(x_3 + i x_4)e^{im\theta_2};\ldots;(x_{l-1} + i x_l)e^{im\theta_{l/2}}\right]^T\] <p>Dans cette équation, $l$ représente la dimension des embeddings, $\theta_k = 10000^{-2k/l}$, et $i$ est l’unité imaginaire. Pour le calcul du score d’attention, RoPE considère la partie réelle du produit, spécifiquement $\operatorname{Re}\left(f(q_m, m)^T f(k_n, n)\right)$. La fonction trigonométrique $\cos((m-n) \theta)$ est périodique, d’où la waveform qu’on obtient. pour certaines valeurs de $(m−n)$, le cosinus (et le sinus) prend des valeurs élevées (les “pics”), tandis que pour d’autres il prend des valeurs faibles (les “creux”). Ainsi, si une information cruciale se trouve à une position qui correspond à un trough de l’oscillation, son score d’attention sera relativement bas. La fréquence des oscillations est modulée par rapport à $\theta_k$: Donc ce qui se fait couramment pour contrebalancer ça, c’est de prendre plusieurs bases de $\theta$, qui fixe l’échelle exponentielle à laquelle les fréquences décroissent.</p> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/periodic_attn.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/periodic_attn.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Ainsi, plusieurs approches visent à contre-balancer le biais positionnel induit par RoPE:</p> <ul> <li> <p><strong>Attention Bucket</strong> (<a href="https://arxiv.org/pdf/2312.04455" rel="external nofollow noopener" target="_blank">2312.04455</a>)<br> Plusieurs bases $\theta$ traitées en parallèle.</p> </li> <li> <p><strong>MS-PoE</strong> (<a href="https://arxiv.org/pdf/2403.04797" rel="external nofollow noopener" target="_blank">2403.04797</a>)<br> C’est une approche qui applique un facteur $r$ à la position des tokens par tête, modifiant du coup l’oscillation par tête $m/r \theta$ afin de garder la base RoPE sur laquelle a été entraîné le modèle (dans une approche de correction du biais à l’inférence)</p> <div class="col-md-6"> </div> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/ms_poe.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/ms_poe.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>&lt;/div&gt;</p> <div class="col-md-6"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/attn_bucket.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/attn_bucket.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <h2 id="2-jouer-sur-les-données">2. Jouer sur les données</h2> <ul> <li> <p><strong>IN2 training</strong> (<a href="https://arxiv.org/pdf/2404.16811" rel="external nofollow noopener" target="_blank">2404.16811</a>)<br> Fine-tuning sur des QA avec contextes longs formés par concaténation aléatoire de segments courts.</p> </li> <li> <p><strong>Réordonnancement des documents</strong> (<a href="https://aclanthology.org/2024.acl-long.91.pdf" rel="external nofollow noopener" target="_blank">ACL-Long’24</a>)<br> Placer les plus pertinents en début ou fin de prompt.</p> </li> </ul> <h1 id="introduction-du-papier--mitigate-positional-biais-via-scaling-a-single-dimension-">Introduction du papier « Mitigate Positional Biais via Scaling a Single Dimension »</h1> <ul> <li>Le biais positionnel provient des patterns d’attention (focus sur début/fin).</li> <li>Causal mask + encodage positionnel génèrent des “dimensions positionnelles” dans les hidden-states.</li> <li> <strong>Objectifs</strong> : <ol> <li>Identifier ces dimensions.</li> <li>Les modifier (scaling) pour diminuer le biais.</li> </ol> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/pos_hidden_state.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/pos_hidden_state.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="tâche-de-retrieval-utilisée">Tâche de retrieval utilisée</h2> <ul> <li> <strong>Clés/valeurs aléatoires</strong> pour isoler le pure retrieval.</li> <li> <p>On mesure</p> \[A_G = \frac{1}{|G|} \sum_{j\in G} a_{l,j}\] <p>où $l$=dernier token (interrogateur), $G$=positions de la clé, $a_{l,j}$=poids d’attention.</p> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/task.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/task.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="identification-des-dimensions-positionnelles">Identification des dimensions positionnelles</h2> <ol> <li> <strong>Monotonie</strong> : $h(p)$ doit être strictement croissante ou décroissante.</li> <li> <strong>Smoothness</strong> : dérivée seconde faible (évolution “douce”).</li> <li> <p>Choix de la dimension $t$ et de l’échelle $s&lt;1$ minimisant la perte</p> \[\arg\min_{h_t,s&lt;1} \mathbb{E}\left[\sum_{i=1}^{|P|} \mathcal{L}(x,y,p_i; F(\theta,h_t,s))\right]\] <p>avec $F(\theta,h_t,s)$ le modèle scaled sur la $t$-ième dimension.</p> </li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/algo.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/algo.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="construction-de-hp_i">Construction de $h(p_i)$</h2> <ul> <li>Approximation par <strong>moindres carrés segmentés</strong> pour lisser le signal.</li> <li>Hypothèse : $\textbf{hidden_state}_i = h(p_i) + \epsilon_i$.</li> <li>Permet de distinguer tendance monotone et bruit.</li> </ul> <h2 id="résultats-de-lidentification">Résultats de l’identification</h2> <ul> <li>Tendance monotone dès la couche 1, s’amplifie dans les couches supérieures.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/example_mistral.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/example_mistral.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="dimensions-causées-par-le-masque-causal">Dimensions causées par le masque causal</h2> <ul> <li>Réduction du PE de 200 pour positions 400–600 : effet mineur.</li> <li>Rogner le masque causal pour ces positions : fortes fluctuations.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/causal_mask_modification_perturb_pos_dim.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/causal_mask_modification_perturb_pos_dim.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="correction-proposée">Correction proposée</h2> <ul> <li>Prouvé que la performance biasée vient des patterns d’attention : en doublant le score à la position 25, on déplace l’attention.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/attn_weights_distrib.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/attn_weights_distrib.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <p><strong>Modification</strong> : scaler la dimension $p$ uniquement pour le calcul du score d’attention du dernier token $l$ :</p> \[z = \begin{cases} \mathrm{Softmax}\left((q_i K^\top + \mathrm{Mask})/\sqrt d\right)V, &amp; i&lt;l,\\ \mathrm{Softmax}\left((\bar q_l\;\bar K^\top)/\sqrt d\right)V, &amp; i=l. \end{cases}\] </li> </ul> <h2 id="effet-du-scaling">Effet du scaling</h2> <ul> <li>$s&gt;1$ → focus début ; $s&lt;0$ → focus fin.</li> <li>$s\in[-1,0.5]$ → distribution équilibrée.</li> </ul> <div class="col-md-6"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/scaling_pos_hidden_states.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/scaling_pos_hidden_states.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-md-6"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/scaling_factor.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/scaling_factor.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <ul> <li> <strong>Varie selon les modèles</strong> :</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/examples_scaling_factors.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/examples_scaling_factors.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="performances">Performances</h2> <p>Gain significatif sur LongBench :</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/longbench_perf.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/longbench_perf.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="limitations-selon-moi">Limitations (selon moi)</h2> <ol> <li>Hypothèses de monotonie et smoothness de $h(p)$ très discutables et infondées.</li> <li>Lien causal masque =&gt; hidden-states pas rigoureusement démontré. le fait qu’il y ait du biais positionnel dans les états cachés est un postulat de départ de ce papier non prouvé proprement.</li> <li>Approche de scaling de “la dimension positionnelle” discutable</li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/limits-480.webp 480w,/assets/img/positional_biais/limits-800.webp 800w,/assets/img/positional_biais/limits-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/positional_biais/limits.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="points-forts-du-papier">Points forts du papier</h2> <ul> <li>Séparation mécanique sémantique vs. position. Un autre papier étudie cette séparation pour comprendre quelle tête ont les parties positionnelles et sémantiques dans les transformers (notamment l’aspect low-rank et low-frequency de la partie positionnelle): <a href="https://openreview.net/pdf?id=1M0qIxVKf6" rel="external nofollow noopener" target="_blank">Uncovering hidden geometry in Transformers via disentangling position and context</a>. Un autre papier (<a href="https://openreview.net/pdf?id=zeYyq0GpXO" rel="external nofollow noopener" target="_blank">Exploring Context Window of Large Language Models via Decomposed Positional Vectors</a>) cherche à décomposer les états cachés de chaque token en partie sémantique et positionnelle en faisant une estimation empirique des vecteurs positionnels sur un grand nombre d’exemples.</li> <li>Peu de papiers visent à corriger le biais positionnel dû au masque causal, donc j’ai trouvé ce papier intéressant qui s’attaque à cela au lieu de s’attaquer au biais positionnel dû à l’encodage positionnel.</li> </ul> <h1 id="pour-aller-plus-loin--découpler-sémantique-et-position">Pour aller plus loin : découpler sémantique et position</h1> <h2 id="spline-based-transformers-eccv25">Spline-based Transformers (ECCV’25)</h2> <ul> <li>Suppression de l’encodage positionnel.</li> <li> <p>Introduction de <em>tokens de contrôle</em> formant une spline :</p> \[s(t)=\sum_{i=0}^n N_{i,k}(t)\,\mathbf p_i\] </li> <li>Position implicite via la géométrie.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/positional_biais/spline_based_transformers.PNG" sizes="95vw"></source> <img src="/assets/img/positional_biais/spline_based_transformers.PNG" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="decomposed-positional-vectors-neurips">Decomposed Positional Vectors (NeurIPS)</h2> <ul> <li>Décomposition : $h_{l,t}=p_{l,t}+cs_{l,t}$.</li> <li>Estimation : $p_{l,t}=\frac{1}{N}\sum_{s=1}^N h^{(s)}_{l,t}$.</li> <li>Isolation : $cs_{l,t}=h_{l,t}-p_{l,t}$.</li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'camillebrl/camillebrl.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Camille Barboule. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/lightbox2@2.11.5/dist/js/lightbox.min.js" integrity="sha256-A6jI5V9s1JznkWwsBaRK8kSeXLgIqQfxfnvdDOZEURY=" crossorigin="anonymous"></script> <script defer src="/assets/js/photoswipe-setup.js" type="module"></script> <script defer src="https://cdn.jsdelivr.net/npm/spotlight.js@0.7.8/dist/spotlight.bundle.min.js" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/venobox@2.1.8/dist/venobox.min.js" integrity="sha256-LsGXHsHMMmTcz3KqTaWvLv6ome+7pRiic2LPnzTfiSo=" crossorigin="anonymous"></script> <script defer src="/assets/js/venobox-setup.js?897c1d9c0b6fcf82b949511c1609d055" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> <script>
      document.addEventListener('DOMContentLoaded', function() {
        // Fonction pour créer un ID à partir du texte (compatible avec Jekyll slugify)
        function createId(text) {
          return text.trim()
            .toLowerCase()
            .normalize('NFD').replace(/[\u0300-\u036f]/g, '') // Enlever les accents
            .replace(/[^\w\s-]/g, '') // Enlever les caractères spéciaux
            .replace(/\s+/g, '-') // Remplacer les espaces par des tirets
            .replace(/-+/g, '-') // Éviter les tirets multiples
            .replace(/^-|-$/g, ''); // Enlever les tirets au début et à la fin
        }
        
        // Fonction pour décoder et normaliser une ancre d'URL
        function normalizeAnchor(anchor) {
          try {
            // Décoder l'URL
            const decoded = decodeURIComponent(anchor);
            // Appliquer la même normalisation que createId
            return createId(decoded);
          } catch (e) {
            return anchor;
          }
        }
        
        // Récupérer tous les headers dans l'article
        const article = document.querySelector('d-article');
        const headers = article.querySelectorAll('h1, h2, h3, h4, h5, h6');
        const tocContainer = document.getElementById('toc-container');
        
        if (headers.length === 0) return;
        
        // Filtrer les headers pour exclure ceux dans d-contents et d-title
        const filteredHeaders = Array.from(headers).filter(header => {
          return !header.closest('d-contents') && !header.closest('d-title');
        });
        
        if (filteredHeaders.length === 0) return;
        
        // Structure pour construire la hiérarchie
        let currentList = document.createElement('ul');
        tocContainer.appendChild(currentList);
        
        let stack = [{level: 0, list: currentList}];
        
        filteredHeaders.forEach((header) => {
          // Ajouter un ID au header s'il n'en a pas
          if (!header.id) {
            header.id = createId(header.textContent);
          }
          
          // Déterminer le niveau (h1=1, h2=2, etc.)
          const level = parseInt(header.tagName.substring(1));
          
          // Gérer la hiérarchie
          while (stack.length > 1 && stack[stack.length - 1].level >= level) {
            stack.pop();
          }
          
          // Si on descend dans la hiérarchie
          if (stack[stack.length - 1].level < level) {
            const newList = document.createElement('ul');
            const lastItem = stack[stack.length - 1].list.lastElementChild;
            if (lastItem) {
              lastItem.appendChild(newList);
            } else {
              stack[stack.length - 1].list.appendChild(newList);
            }
            stack.push({level: level, list: newList});
          }
          
          // Créer l'élément de liste
          const listItem = document.createElement('li');
          const link = document.createElement('a');
          link.href = '#' + header.id;
          link.textContent = header.textContent;
          link.addEventListener('click', function(e) {
            e.preventDefault();
            header.scrollIntoView({ behavior: 'smooth', block: 'start' });
          });
          
          listItem.appendChild(link);
          stack[stack.length - 1].list.appendChild(listItem);
        });
        
        // Nettoyer les listes vides
        const emptyLists = tocContainer.querySelectorAll('ul:empty');
        emptyLists.forEach(list => list.remove());
        
        // Gérer la navigation depuis l'URL
        function navigateToHash() {
          if (window.location.hash) {
            const hash = window.location.hash.substring(1);
            const normalizedHash = normalizeAnchor(hash);
            
            // Essayer de trouver l'élément par ID normalisé
            let targetElement = document.getElementById(normalizedHash);
            
            // Si pas trouvé, essayer avec le hash original
            if (!targetElement) {
              targetElement = document.getElementById(hash);
            }
            
            // Si toujours pas trouvé, chercher dans tous les headers
            if (!targetElement) {
              filteredHeaders.forEach(header => {
                if (createId(header.textContent) === normalizedHash) {
                  targetElement = header;
                }
              });
            }
            
            if (targetElement) {
              setTimeout(() => {
                targetElement.scrollIntoView({ behavior: 'smooth', block: 'start' });
              }, 100);
            }
          }
        }
        
        // Naviguer au chargement de la page
        navigateToHash();
        
        // Écouter les changements de hash
        window.addEventListener('hashchange', navigateToHash);
      });
    </script> </body> </html>