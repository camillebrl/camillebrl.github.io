<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="fr"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://camillebrl.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://camillebrl.github.io/" rel="alternate" type="text/html" hreflang="fr"/><updated>2025-06-26T16:09:24+00:00</updated><id>https://camillebrl.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Les approches d’explicabilité par les exemples appliquées aux LLMs</title><link href="https://camillebrl.github.io/blog/2025/formatting-and-links/" rel="alternate" type="text/html" title="Les approches d’explicabilité par les exemples appliquées aux LLMs"/><published>2025-06-16T18:00:00+00:00</published><updated>2025-06-16T18:00:00+00:00</updated><id>https://camillebrl.github.io/blog/2025/formatting-and-links</id><content type="html" xml:base="https://camillebrl.github.io/blog/2025/formatting-and-links/"><![CDATA[<p>Un LLM génère des tokens à partir d’autres tokens selon un processus probabiliste. Pour chaque séquence de tokens fournie en entrée, le modèle retourne une distribution de probabilité sur l’ensemble des tokens suivants possibles. Un token représente un élément du vocabulaire du modèle, dont la taille est fixe et définie dans la configuration du tokenizer ou du modèle lui-même.</p> <p>Prenons l’exemple des modèles Qwen avec un vocabulaire de 151 936 tokens : à chaque étape de génération, le modèle calcule une distribution de probabilité sur ces 151 936 possibilités. De manière autorégressive, chaque nouveau token généré est ajouté à la séquence d’entrée pour prédire le suivant, et ainsi de suite.</p> <p>Comprendre pourquoi un modèle génère certains tokens plutôt que d’autres soulève plusieurs questions cruciales. La séquence d’entrée (prompt) peut contenir des éléments variés, notamment des chunks de texte dans le cas du RAG (Retrieval-Augmented Generation), qui servent de contexte pour répondre aux questions. Pour véritablement comprendre le processus de génération, nous devons répondre à trois interrogations principales :</p> <ul> <li> <p>Quelles parties spécifiques du prompt influencent la génération de quels tokens ? Cette question est particulièrement pertinente dans le contexte du RAG où différents passages peuvent avoir des impacts variés sur la réponse finale.</p> </li> <li> <p>Sur quelles connaissances acquises pendant l’entraînement le modèle s’appuie-t-il pour générer chaque token ? Comment distinguer ce qui provient du prompt de ce qui provient de la mémoire du modèle ?</p> </li> <li> <p>Quelles parties du modèle (couches, têtes d’attention, neurones) sont responsables de quelles décisions ? Pourquoi des modèles de tailles différentes, même issus de la même famille, produisent-ils des réponses différentes ?</p> </li> </ul> <p>Pour répondre à ces questions, nous devons nous tourner vers les approches d’explicabilité, et plus particulièrement l’explicabilité par les données. Cette approche examine deux sources d’influence principales : les données présentes dans le prompt et les données utilisées lors de l’entraînement du modèle. L’objectif est d’établir des liens causaux clairs entre ces sources de données et les tokens générés, qu’ils soient pris individuellement ou en groupes cohérents. Cette compréhension est essentielle pour améliorer la fiabilité, la transparence et le contrôle des systèmes basés sur les LLM.</p> <h2 id="rapide-overview-des-approches-dexplicabilité-par-les-exemples-appliquées-aux-llms">Rapide overview des approches d’explicabilité par les exemples appliquées aux LLMs</h2> <h3 id="approches-tda-training-data-analysis-pour-comprendre-quelles-connaissances-apprises-dans-lentraînement-ont-été-influentes-dans-la-génération-de-quels-tokens">Approches TDA (training data analysis) pour comprendre quelles connaissances apprises dans l’entraînement ont été influentes dans la génération de quels tokens</h3> <ol> <li><strong>Si on cherche à estimer l’impact qu’aurait un exemple d’entraînement sur la perte d’un exemple de test à un exemple d’entraînement</strong> (qu’il soit dans le jeu de données d’entraînement de base ou pas) : $\mathrm{Influence}\bigl(z_{\mathrm{train}}\to z_{\mathrm{test}}\bigr) = \frac{d}{d\varepsilon}\, \mathcal{L}\bigl(z_{\rm test},\,\theta_\varepsilon\bigr) \Big|<em>{\varepsilon=0} = -\,g</em>{\mathrm{test}}^\top\,H_\theta^{-1}\,g_{\mathrm{train}}$. Voir les librairies <a href="https://github.com/pomonam/kronfluence">Kronfluence</a> ou <a href="https://github.com/frederick0329/TracIn">TracIn</a> ou <a href="https://github.com/aleks-krasowski/PINNfluence">PINNfluence</a> ou <a href="https://github.com/TRAIS-Lab/GraSS">GraSS</a>. Des repo github proposent des tutos pour plusieurs de ces lib: cf <a href="https://github.com/deel-ai/influenciae">Influenciae</a>. Les fonctions d’influence permettent de répondre à ces questions: <ul> <li>Est-ce que je devrais ajouter cet exemple dans mon set d’apprentissage pour améliorer les performances de cette prédiction?</li> <li>Quels exemples d’entraînement ont été utiles à la prédiction de mon modèle?</li> <li>Le modèle s’est trompé: sur quels exemples d’entraînement s’est-il basé pour cette mauvaise prédiction?</li> <li>Quel serait l’effet d’une re-labélisation de ma donnée d’entraînement sur la prédiction? Quelles sont les données que je devrais re-labéliser pour améliorer ma prédiction? =&gt; Pour répondre à ces questions, il faut modifier un peu l’approche: $\mathrm{Influence}(\text{relabeling}(z_{\rm train})!\to!z_{\rm test}) = g_{\mathrm{test}}^\top\,H_\theta^{-1}\,\bigl[\nabla_\theta \mathcal{L}\bigl(z_{\text{train}}^{\text{modified}},\,\theta_\varepsilon\bigr) \;-\; \nabla_\theta \mathcal{L}\bigl(z_{\text{train}}^{\text{original}},\,\theta_\varepsilon\bigr)\bigr]$</li> </ul> </li> </ol> <h3 id="approches-danalyse-du-prompt-input-donné-au-modèle-dans-la-génération-de-quels-tokens">Approches d’analyse du prompt (input donné au modèle) dans la génération de quels tokens</h3> <ol> <li> <p><strong>Si on veut estimer sur quelle partie de l’input le modèle s’est basé pour faire sa prédiction</strong>, on utilise des approches de cartes de saillance. En gros, on mesure comment la sortie du modèle $f(x)$ varie si on modifie chaque composante $x_i$ de l’entrée. Pour se faire, des libraires comme <a href="https://github.com/pytorch/captum">Captum</a> ou <a href="https://github.com/inseq-team/inseq">Inseq</a> ou <a href="https://github.com/jacobgil/pytorch-grad-cam">Grad-cam</a> ou <a href="https://github.com/albermax/innvestigate">Investigate</a> ou <a href="https://github.com/SeldonIO/alibi">Alibi</a> existent.</p> </li> <li> <p><strong>Si on veut mesurer la contribution de chaque feature / chaque pixel d’image / chaque token de texte à la prédiction finale du modèle</strong>, on utilise les valeurs de Shapley. Les librairies qui permettent d’obtenir les valeurs de Shapley sont <a href="https://github.com/pytorch/captum">Captum</a>, <a href="https://github.com/SeldonIO/alibi">Alibi</a>, <a href="https://github.com/shap/shap">SHAP</a>.</p> </li> </ol> <h2 id="1-estimation-de-limpact-dun-exemple-dentraînement-sur-la-prédiction-dun-exemple-de-test-influence-functions">1. Estimation de l’impact d’un exemple d’entraînement sur la prédiction d’un exemple de test: Influence functions</h2> <h3 id="11-introduction-sur-les-fonctions-dinfluence">1.1 Introduction sur les fonctions d’influence</h3> <p>Pour introduire les fonctions d’influence appliquées au deep learning, nous nous basons sur le le papier <a href="https://arxiv.org/pdf/1703.04730">Understanding Black-box Predictions via Influence Functions</a>, et notamment sur l’annexe A pour expliquer les différentes formules.</p> <blockquote> <table> <tbody> <tr> <td>**L’influence de $z_{\rm train}$ sur $z_{\rm test}$ ($\mathrm{Influence}(z_{\rm train}!\to!z_{\rm test})$) se définit comme $\frac{d}{d\varepsilon}\, \mathcal{L}\bigl(z_{\rm test},\ \theta_\varepsilon\bigr) \Big</td> <td><em>{\varepsilon=0}$. En d’autres termes, elle mesure la sensibilité de la loss de $z</em>{\rm test}$ (ou de n’importe quelle fonction $f(\theta)$ avec $\theta$ les poids du modèle : $\mathrm{Influence}(z_{\rm train}!\to!f(\theta))$) à l’”up-weight” infinitésimal (d’un $\varepsilon$ proche de 0) de la loss de $z_{\rm train}$. En gros, si modifiait le poids qu’on donne à la loss sur $z_{\rm train}$ dans le modèle, comment varierait la loss de $z_{\text{test}}$ (ou la fonction $f(\theta)$) ?**</td> </tr> </tbody> </table> </blockquote> <p>A noter:</p> <ul> <li>C’est l’<strong>impact de l”up-weight” de la loss sur $z_\text{train}$ sur qqch qu’on mesure avec les fonctions d’influence</strong>. En fait pour mesurer l’impact de l”up-weight” de $z_{\text{train}}$ dans la loss globale, on se pose la question: “on se pose la question : “<strong>si je donnais un peu plus de poids à ce terme de loss dans l’objectif global, comment cela ferait-il bouger mes paramètres et, avec ces nouveaux paramètres, ma performance sur un point de test, ou sur une fonction?</strong>”. En effet, en deep learning, modifier le poids d’une donnée dans l’entraînement, c’est modifier le poids qu’on donne à sa loss dans l’apprentissage.</li> <li>$f(\theta)$ peut être n’importe quelle fonction (exemple: la moyenne des prédictions sur un ensemble de données types (cf le papier <a href="https://arxiv.org/pdf/2505.19949">Which Data Attributes Stimulate Math and Code Reasoning? An Investigation via Influence Functions</a> qui cherche à calculer l’influence des textes d’entraînement sur la génération de code (moyenne de des log probabilité de la génération de chaque token de code générés dans un benchmark sachant un problème de code en langage naturel à résoudre)), la différence entre 2 prédictions du modèle, …)</li> </ul> <p>On a la formule de l’influence: \(\mathrm{Influence}\bigl(z_{\mathrm{train}}\to z_{\mathrm{test}}\bigr) = I_{z_\text{test}}\bigl(z_{\mathrm{train}}\bigr) = -\,g_{\mathrm{test}}^\top\,H_\theta^{-1}\,g_{\mathrm{train}}.\) Avec: \(g_{\mathrm{test}} \;=\; \nabla_\theta \,\mathcal{L}\bigl(z_{\mathrm{test}},\,\theta_\varepsilon\bigr)\,.\) \(g_{\mathrm{train}} \;=\; \nabla_\theta \mathcal{L}(z_{\rm train},\theta_\varepsilon)\) <strong>Détaillon un peu comment on a obtenu cette formule…</strong></p> <table> <tbody> <tr> <td>On cherche $\frac{d}{d\varepsilon}\, \mathcal{L}\bigl(z_{\rm test},\ \theta_\varepsilon\bigr) \Big</td> <td><em>{\varepsilon=0}$. On peut voir ça comme $\frac{d}{d\varepsilon} f(g(\varepsilon))$ avec $g(\varepsilon) = \theta</em>\varepsilon$ et $f(\theta_\varepsilon) = \mathcal{L}(z_{\rm test},\theta_\varepsilon)$, d’où, par chain rule: $f’(g(\varepsilon)) = f’\bigl(g(\varepsilon)\bigr)\,g’(\varepsilon)$.</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>Donc on a $\frac{d}{d\varepsilon}\, \mathcal{L}\bigl(z_{\rm test},\ \theta_\varepsilon\bigr) \Big</td> <td><em>{\varepsilon=0}= \nabla</em>\theta \mathcal{L}(z_{\rm test}, \theta_\varepsilon)\Big</td> <td><em>{\varepsilon=0} \times \frac{d}{d\varepsilon} \theta</em>\varepsilon \Big</td> <td>_{\varepsilon=0}$.</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>Du coup, dans un premier temps, il nous faut calculer $\frac{d}{d\varepsilon} \theta_\varepsilon \Big</td> <td><em>{\varepsilon=0}$. Et ensuite on le multipliera à $\nabla</em>\theta \mathcal{L}(z_{\rm test}, \theta_\varepsilon)\Big</td> <td>_{\varepsilon=0}$ qu’on sait calculer vu que c’est au voisinage de $\theta$, les poids du modèle de base.</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>**D’abord, commençons par calculer $\frac{d}{d\varepsilon} \theta_\varepsilon \Big</td> <td><em>{\varepsilon=0}$, en gros: comment $\theta</em>\varepsilon$ varie autour de $\theta$ quand on up-weight très lélègement (voisinage de 0) la loss de notre loss de l’exemple $z_\text{train}$:**</td> </tr> </tbody> </table> <blockquote> <p>Pour faire cet “up-weight” de la loss de $z_{\text{train}}$ d’un tout petit $\varepsilon$, on perturbe la fonction de perte en ajoutant un petit coefficient $\varepsilon$ sur la perte de $z_{\rm train}$ et on voit comment les paramètres optimaux $\theta$ évoluent avec $\varepsilon$.</p> </blockquote> <p>On repart de ce que ça veut dire de “perturber la fonction de perte en ajoutant un petit coefficient $\varepsilon$ sur la perte de $z_{\rm train}$”: on obtient une nouvelle la loss totale du modèle ($R_\varepsilon(\theta)$) avec les nouveau poid $\varepsilon$ donné à la loss de $z_{\text{train}}$: \(R_\varepsilon(\theta) = \frac{1}{n}\sum_{i=1}^n \mathcal{L}(z_i,\theta) \;+\;\varepsilon\,\mathcal{L}(z_{\rm train},\theta).\)</p> <p>Puis, on cherche les poids $\theta_\varepsilon$ qui minimisent cette nouvelle loss: \(\theta_\varepsilon \;=\; \arg\min_{\theta}\;R_\varepsilon(\theta)\)</p> <p>Ce qui revient à chercher les $\theta_\varepsilon$ dont le gradient de cette nouvelle loss en $\theta$ est nul, car $\theta_\varepsilon$ est un minimum local de $R_\varepsilon$ si et seulement si sa dérivée première (gradient) s’annule: \(\nabla_\theta R_\varepsilon\bigl(\theta_\varepsilon\bigr) = 0.\) En développant:</p> \[\frac{1}{n}\sum_{i=1}^n \nabla_\theta \mathcal{L}(z_i,\theta_\varepsilon) \;+\;\varepsilon\,\nabla_\theta \mathcal{L}(z_{\rm train},\theta_\varepsilon) = 0.\] <p>Ici, si on peut faire une approximation de Taylor en $\theta$ de $\frac{1}{n}\sum_{i=1}^n \nabla_\theta \mathcal{L}(z_i,\theta_\varepsilon) \;+\;\varepsilon\,\nabla_\theta \mathcal{L}(z_{\rm train},\theta_\varepsilon)$, puisqu’on veut voir la modification de $\theta_\varepsilon$ pour un tout petit $\varepsilon$, ie proche de 0, donc $\theta_\varepsilon$ proche de $\theta$.</p> <p>Le formule de Taylor à l’ordre 1 nous donne: \(f(x) \approx f(x_0) + f'(x_0)\,(x - x_0)\)</p> <p>D’où, en approximant avec Taylor à l’ordre 1 $\frac{1}{n}\sum_{i=1}^n \nabla_\theta \mathcal{L}(z_i,\theta_\varepsilon) \;+\;\varepsilon\,\nabla_\theta \mathcal{L}(z_{\rm train},\theta_\varepsilon)$ en $\theta$, on obtient:</p> \[[ \frac{1}{n}\sum_{i=1}^n \nabla_\theta \mathcal{L}(z_i,\theta) \;+\;\varepsilon\,\nabla_\theta \mathcal{L}(z_{\rm train},\theta) ] \\ + \; \;(\theta_\varepsilon - \theta) \;\; [ \frac{1}{n}\sum_{i=1}^n \nabla²_\theta \mathcal{L}(z_i,\theta_\varepsilon) \;+\;\varepsilon\,\nabla²_\theta \mathcal{L}(z_{\rm train},\theta_\varepsilon) ]\] <p>On a donc: $$ [ \frac{1}{n}\sum_{i=1}^n \nabla_\theta \mathcal{L}(z_i,\theta) \;+\;\varepsilon\,\nabla_\theta \mathcal{L}(z_{\rm train},\theta) ] \;\;</p> <ul> <li>\; \;(\theta_\varepsilon - \theta) \;\; [ \frac{1}{n}\sum_{i=1}^n \nabla²<em>\theta \mathcal{L}(z_i,\theta</em>\varepsilon) \;+\;\varepsilon\,\nabla²<em>\theta \mathcal{L}(z</em>{\rm train},\theta_\varepsilon) ] \; = \; 0 \(D'où:\) (\theta_\varepsilon - \theta) = - [ \frac{1}{n}\sum_{i=1}^n \nabla_\theta \mathcal{L}(z_i,\theta) \;+\;\varepsilon\,\nabla_\theta \mathcal{L}(z_{\rm train},\theta) ] \times [ \frac{1}{n}\sum_{i=1}^n \nabla²<em>\theta \mathcal{L}(z_i,\theta</em>\varepsilon) \;+\;\varepsilon\,\nabla²<em>\theta \mathcal{L}(z</em>{\rm train},\theta_\varepsilon) ]^{-1} $$</li> </ul> <p>Or, puisque $\theta$ sont les poids optimaux pour le modèle de base, $\frac{1}{n}\sum_{i=1}^n \nabla_\theta \mathcal{L}(z_i,\theta) = 0$ et $\varepsilon\,\nabla²<em>\theta \mathcal{L}(z</em>{\rm train},\theta_\varepsilon) = 0$:</p> \[(\theta_\varepsilon - \theta) = - \varepsilon\,\nabla_\theta \mathcal{L}(z_{\rm train},\theta) \times [\frac{1}{n}\sum_{i=1}^n \nabla²_\theta \mathcal{L}(z_i,\theta_\varepsilon)]^{-1}\] <p>Et si on dérive par rapport à $\varepsilon$ on obtient:</p> \[\frac{d}{d\varepsilon}(\theta_\varepsilon - \theta) = - \nabla_\theta \mathcal{L}(z_{\rm train},\theta) \times [\frac{1}{n}\sum_{i=1}^n \nabla²_\theta \mathcal{L}(z_i,\theta_\varepsilon)]^{-1} = - \nabla_\theta \mathcal{L}(z_{\rm train},\theta) H_\theta^{-1}\] <p>Or $\frac{d}{d\varepsilon}(\theta_\varepsilon - \theta) = \frac{d}{d\varepsilon} \theta_\varepsilon$</p> <p>D’où : \(\frac{d}{d\varepsilon} \theta_\varepsilon = - \nabla_\theta \mathcal{L}(z_{\rm train},\theta) H_\theta^{-1}\)</p> <p>Ainsi, quand on multiplie par $\nabla_\theta \,\mathcal{L}\bigl(z_{\mathrm{test}},\,\theta_\varepsilon\bigr)$ on obtient a la formule de l’influence: \(\mathrm{Influence}\bigl(z_{\mathrm{train}}\to z_{\mathrm{test}}\bigr) = I_{z_\text{test}}\bigl(z_{\mathrm{train}}\bigr) = \frac{d}{d\varepsilon}\, \mathcal{L}\bigl(z_{\rm test},\ \theta_\varepsilon\bigr) \Big|_{\varepsilon=0} = -\nabla_\theta \,\mathcal{L}\bigl(z_{\mathrm{test}},\,\theta_\varepsilon\bigr)H_\theta^{-1}\nabla_\theta \mathcal{L}(z_{\rm train},\theta_\varepsilon)\) ou: \(\mathrm{Influence}\bigl(z_{\mathrm{train}}\to f(\theta)\bigr) = I_f(z_{\mathrm{train}}) = \frac{d}{d\varepsilon}\, f(\theta_\varepsilon) \Big|_{\varepsilon=0} = -\nabla_\theta \,f(\theta_\varepsilon)H_\theta^{-1}\nabla_\theta \mathcal{L}(z_{\rm train},\theta_\varepsilon)\)</p> <p>Le papier <a href="https://arxiv.org/pdf/2209.05364">If Influence Functions are the Answer, Then What is the Question?</a> explique ensuite que les functions d’influence n’approximent pas fidèlement le retraining « leave-one-out », mais qu’elles correspondent en fait au proximal Bregman response function (PBRF). [A FINIR]</p> <h3 id="12-comment-calcule-t-on-linverse-de-la-hessienne-en-deep-learning">1.2 Comment calcule-t-on l’inverse de la hessienne en deep learning</h3> <h4 id="121-hesienne-pas-forcément-inversible">1.2.1 Hesienne pas forcément inversible…</h4> <p>Dans les réseaux de neurones, la loss d’entraînement n’est pas fortement convexe (le minimum local n’est pas forcément un minimum global…) donc la hessienne peut être non inversible. Donc, des approches ont été étudiées pour garantir l’inversibilité de la hessienne, en ajoutant notamment un terme dit de “damping” $\lambda &gt;0$.</p> <h4 id="122-hessienne-par-rapport-aux-paramètres-du-réseau-compliquée-à-calculer-pour-des-réseaux-avec-un-grand-nombre-de-paramètres">1.2.2 Hessienne par rapport aux paramètres du réseau compliquée à calculer pour des réseaux avec un grand nombre de paramètres…</h4> <p>Le papier <a href="https://arxiv.org/pdf/2209.05364">If Influence Functions are the Answer, Then What is the Question?</a> propose d’approximer la Hessienne par la Hessienne de Gauss–Newton (GNH), notée $G_\theta$ :</p> \[G_\theta = J_{y\theta}^T \, H_y \, J_{y\theta}\] <p>où :</p> <ul> <li>$J_{y\theta}$ est la matrice Jacobienne des sorties du réseau par rapport aux paramètres ;</li> <li>$H_y = \nabla^2_y \mathcal{L}(y, \theta)$ est la Hessienne de la fonction de coût par rapport aux sorties du réseau. propose d’approximer la Hessienne par la matrice d’information de Fisher (équivalente à la Hessienne de Gauss-Newton).</li> </ul> <p>En fait, on a:</p> \[\underbrace{H_\theta}_{\text{Très difficile}} =\;\;\; \underbrace{J_{y\theta}^T \, H_y \, J_{y\theta}}_{\text{Facile (GNH)}} \;\;\;+ \underbrace{\sum_i \frac{\partial \mathcal{L}}{\partial y_i} \,\nabla_\theta^2 y_i}_{\text{Cauchemar computationnel}}\] <p>avec:</p> <ul> <li>$J_{y\theta}$ : Déjà calculé par backpropagation standard</li> <li>$H_y$ : Matrice $k \times k$ avec $k =$ le nombre de tokens possibles (ex : 151936 pour Qwen)</li> </ul> <p>Afin de ne pas calculer les dérivées secondes à travers tout le réseau (ce qui est très coûteux quand on a beaucoup de paramètres), on utilise, pour l’ensemble des calculs d’influence (surtout pour les LLMs), ce résultat:</p> \[H_\theta^{-1}\approx \bigl(G_\theta + \lambda I\bigr)^{-1}.\] <h4 id="123-factorisation-par-blocs-de-g_theta-et-factorisation-en-produit-de-kronecker-pour-pourvoir-stocker-cette-matrice--paralléliser-les-calculs-entre-couches">1.2.3 Factorisation par blocs de $G_\theta$ et factorisation en produit de Kronecker pour pourvoir stocker cette matrice &amp; paralléliser les calculs entre couches</h4> <p>Au lieu d’inverser directement la grande matrice $\,G_\theta+\lambda I$, le papier <a href="https://arxiv.org/pdf/2505.05017">Scalable Multi-Stage Influence Function for Large Language Models via Eigenvalue-Corrected Kronecker-Factored Parameterization</a> exploite sa structure en blocs correspondant à chaque couche du réseau.<br/> \(G = \begin{bmatrix} G_{1,1} &amp; G_{1,2} &amp; \cdots\\ G_{2,1} &amp; G_{2,2} &amp; \\ \vdots &amp; &amp; \ddots \end{bmatrix},\) Pour un réseau à $L$ couches, on a donc $G = [G_{i,j}]<em>{1 \leq i, j \leq L}$, avec $G</em>{i,j}$ qui représente le bloc entre les paramètres de la couche $i$ et de la couche $j$.</p> <p>Cette séparation en bloc permet au papier de simplifier $G$ en ne gardant que les blocs diagonaux :</p> \[G \approx \tilde{G} = \mathrm{diag}(G_{1,1}, G_{2,2}, \dots, G_{L,L})\] <p>Cela signifie qu’on ignore les interactions entre différentes couches et qu’on ne considère que les blocs $G_{l,l}$ pour chaque couche $l$.</p> <p>Cette approche par blocs permet :</p> <ul> <li>De traiter chaque couche indépendamment</li> <li>D’éviter de stocker/calculer la matrice complète de taille $p \times p$ (où $p$ est nombre total de paramètres)</li> <li>De paralléliser les calculs entre couches</li> </ul> <p>C’est ce qui rend la méthode scalable pour les grands modèles comme les LLMs avec des milliards (plutôt même billions…) de paramètres.</p> <h3 id="13-le-cas-des-llms-besoin-dune-influence-token-wise-ou-sentence-wise">1.3 Le cas des LLMs: besoin d’une influence token-wise ou sentence-wise</h3> <p>Le papier <a href="https://arxiv.org/pdf/2308.03296">Studying Large Language Model Generalization with Influence Functions</a> présente l’application des fonctions d’influence aux LLMs. Dans le cas des LLMs, la loss est la negative log-vraisemblance. La première particularité d’un LLM, c’est le fait qu’un datapoint est un peu compliqué à définir. On peut supposer qu’il s’agit d’une phrase (et son label, le token suivant la phrase), ou on peut considérer le token lui-même (l’input étant la phrase le précédent, le label le token en question, par exemple). Mais il est important de bien définir de quoi on parle quand on parle de “datapoint”.</p> <h4 id="131-linfluence-à-léchelle-de-la-phrase-z_m">1.3.1 L’influence à l’échelle de la phrase $z_m$</h4> <p>Supposons que $z_m$ soit cette phrase “le chat est gris”, soit ce datapoint:</p> \[[\text{BOS, le, chat, est, gris}] \rightarrow \text{[EOS]}\] <p>Vu qu’on est dans un cas autorégressif (c’est-à-dire que les tokens sont prédits à partir des tokens précédents de la séquence) :</p> <p>Si $z_m$ de taille $T$ :</p> \[\nabla_\theta L(z_m, \theta) = \sum_{t=1}^T(-\nabla_\theta \log p(z_{m,t} \mid z_{m, &lt;t}, \theta))\] <p>Nous, $z_m$ est de taille 6 :</p> \[\nabla_\theta L(z_m, \theta) = \\ -\nabla_\theta \log p(\text{le} \mid \text{[BOS]}, \theta) \\ \quad - \nabla_\theta \log p(\text{chat} \mid \text{[[BOS], le]}, \theta) \\ \quad - \nabla_\theta \log p(\text{est} \mid \text{[BOS], le, chat}, \theta) \\ \quad - \nabla_\theta \log p(\text{gris} \mid \text{[BOS], le, chat, est}, \theta) \\ \quad - \nabla_\theta \log p(\text{[EOS]} \mid \text{[BOS], le, chat, est, gris}, \theta)\] <h4 id="132-linfluence-à-léchelle-des-tokens-t-dans-la-phrase-z_m">1.3.2 L’influence à l’échelle des tokens $t$ dans la phrase $z_m$</h4> <p>On peut aussi considérer l’échelle du token, comme on l’a mis plus haut, en considérant l’input comme étant la phrase précédant ce token, et le label ce token en question.</p> <p>On a ici $\nabla_\theta L(z_m, \theta)$ qui est la somme des gradients de la loss au niveau de chaque token. Du coup, il suffit de prendre $- \nabla_\theta \log p(\text{gris} \mid \text{[BOS], le, chat, est}, \theta)$ pour avoir l’influence du token gris dans la séquence par exemple. On peut ainsi avoir l’information token par token.</p> <p>Et ça c’est ce qu’on obtient ici (cf <a href="https://arxiv.org/pdf/2308.03296">Studying Large Language Model Generalization with Influence Functions, Grosse 2023</a>) :</p> \[\nabla_\theta L(\text{token t dans } z_m, \theta) = \nabla_\theta \log p(\text{token t} \mid \text{ce qui est avant token t dans } z_m, \theta)\] <p>On obtient donc la formule:</p> \[I_f(z_{m,t}) = \nabla_{\theta}f(\theta)^{T} H^{-1} \nabla_{\theta}\log p(z_{m,t}\mid z_{m,&lt;t}, \theta)\] <p>Prenons l’exemple suivant: on prend $f = \log p(\text{“hydrogen and oxygen”} \mid \text{“Water is composed of”})$ et $z_m$ qui est le texte ci-dessous. On peut afficher l’influence token par token dans le texte:</p> <h3 id="14-le-cas-des-llms-beaucoup-de-données-dentraînement-eg-36-trillions-de-tokens-pour-qwen3--query-batching-ou-semantic-matching-pour-ne-pas-calculer-linfluence-sur-toutes-les-données-trop-coûteux">1.4 Le cas des LLMs: beaucoup de données d’entraînement (eg. 36 trillions de tokens pour Qwen3) =&gt; query batching ou semantic matching pour ne pas calculer l’influence sur toutes les données (trop coûteux)</h3> <p>Le papier <a href="https://arxiv.org/pdf/2308.03296">Studying Large Language Model Generalization with Influence Functions</a> propose une approche pour éviter de calculer les gradients de tous les exemples d’entraînement candidats pour chaque requête d’influence. Pour cela, ils “filtrent” les données d’entraînement par rapport à la phrase test via un filtrage TF-IDF et une approche qu’ils introduisent de “query batching”.</p> <h4 id="141-le-filtrage-tf-idf">1.4.1 Le filtrage TF-IDF</h4> <p>Le filtrage TF-IDF utilise une technique classique de recherche d’information pour présélectionner les séquences d’entraînement les plus susceptibles d’être influentes. L’intuition derrière est que les séquences pertinentes devraient avoir au moins un certain chevauchement de tokens avec la requête.</p> <p>Ils retiennent les top 10,000 séquences selon le score TF-IDF Calcul d’influence et calculent les influences uniquement sur ces séquences présélectionnées.</p> <h4 id="142-le-query-batching">1.4.2 Le Query-Batching</h4> <p>Dans un LLM, on a beaucoup d’exemples $z_m$ d’entraînement. Donc, on calcule séparemment $∇<em>θ\mathcal{L}(z_m, \theta</em>\varepsilon)$ et $\nabla_{\theta} f(\theta_\varepsilon)^\top \, H^{-1}$ qui se calcule en une fois.</p> <p>Pour stocker de nombreux gradients de requêtes en mémoire ($∇<em>θ\mathcal{L}(z_m, \theta</em>\varepsilon) \; \forall \; z_m$), ils approximent chaque matrice de gradient préconditionné comme étant de rang faible (rank-32 dans leurs expériences).</p> <p>Ainsi, pour chaque requête, ils n’ont pas à refaire les calculs! Ils ont juste à calculer $\nabla_{\theta} f(\theta_\varepsilon)$.</p> <h3 id="15-le-cas-des-llms-plusieurs-couches-dentraînement-pretraining-fine-tuning-alignement---multi-stage-influence-functions">1.5 Le cas des LLMs: plusieurs couches d’entraînement (pretraining, fine-tuning, alignement, …) =&gt; multi-stage influence functions</h3> <p>Le papier <a href="https://arxiv.org/pdf/2505.05017">Scalable Multi-Stage Influence Function for Large Language Models via Eigenvalue-Corrected Kronecker-Factored Parameterization</a> explique que la fonction d’influence classique $I_f(z_{m,t}) = \nabla_{\theta}f(\theta)^{T} H^{-1} \sum_{t=1}^T(-\nabla_\theta \log p(z_{m,t} \mid z_{m, &lt;t}, \theta))$ permet de quantifier l’impact d’une phrase d’entraînement sur les prédictions du modèle. Cependant, on a des modèles qui sont passés par plusieurs phases d’entraînement pour les LLMs (avec plusieurs données différentes). En effet, les LLMs sont pré-entraînés (modèles “base”), puis instruct-tuné (modèles “chat”), puis passent par du reinforcement learning (ou du “faux” réinforcement learning (DPO, …)) pour la phase d’alignement. Donc notre formule ne marche plus si on prend un modèle “chat” par exemple (les 3/4 des modèles qu’on trouve sur huggingface) et qu’on veut calculer l’influence d’une phrase du jeu de pre-entraînement par exemple. Or, ce sont ces données de pré-entraînement qui nous intéressent puisque la majorité des connaissances d’un LLM sont acquises pendant le pré-entraînement. Sans pouvoir les tracer, on ne peut pas expliquer d’où viennent les réponses du modèle.</p> <p>Ainsi, les auteurs du papier proposent une connexion entre l’espace des paramètres du modèle pré-entraîné et celui du modèle fine-tuné. L’intuition est que le fine-tuning ne devrait pas trop éloigner les paramètres de leur état pré-entraîné. On reformule donc l’objectif de fine-tuning avec une contrainte de proximité euclidienne :</p> \[\theta^{ft} = \arg\min_\theta \mathcal{L}_{ft}(\theta) + \frac{\alpha}{2}||\theta - \theta^{pt}||_2^2\] <p>où :</p> <ul> <li>$\mathcal{L}_{ft}(\theta)$ est la loss de fine-tuning</li> <li>$\alpha \in \mathbb{R}^+$ est un hyperparamètre contrôlant la proximité</li> <li> <table> <tbody> <tr> <td>$</td> <td> </td> <td>\theta - \theta^{pt}</td> <td> </td> <td>_2^2$ est la distance euclidienne entre les paramètres du modèle pré-entraîné avec le modèle fine-tuné (final)</td> </tr> </tbody> </table> </li> </ul> <p>Avec cette reformulation, on peut dériver la fonction d’influence multi-étapes :</p> \[I_f(z_m) = \nabla_\theta f(\theta^{ft})^T \left(\nabla^2_\theta \mathcal{L}_{ft}(\theta^{ft}) + \alpha I\right)^{-1} \left(\nabla^2_\theta \mathcal{L}_{pt}(\theta^{pt})\right)^{-1} \nabla_\theta \mathcal{L}(z_m, \theta^{pt})\] <p>Ainsi, on a 2 hessiennes:</p> <ul> <li><strong>Hessienne du pré-entraînement</strong> : $\left(\nabla^2<em>\theta \mathcal{L}</em>{pt}(\theta^{pt})\right)^{-1}$ <ul> <li>Calculée aux paramètres $\theta^{pt}$ (modèle pré-entraîné)</li> <li>Capture la courbure de la loss de pré-entraînement</li> </ul> </li> <li><strong>Hessienne du fine-tuning</strong> : $\left(\nabla^2<em>\theta \mathcal{L}</em>{ft}(\theta^{ft}) + \alpha I\right)^{-1}$ <ul> <li>Calculée aux paramètres $\theta^{ft}$ (modèle fine-tuné)</li> <li>Inclut le terme de régularisation $\alpha I$ qui encode la contrainte de proximité</li> </ul> </li> </ul> <p>Cette double inversion de Hessienne permet de :</p> <ul> <li><strong>Première inversion</strong> : Transformer le gradient de l’exemple de pré-entraînement en changement de paramètres</li> <li><strong>Seconde inversion</strong> : Propager ce changement à travers le fine-tuning pour voir son impact final</li> </ul> <p>C’est comme si on “remontait” l’influence à travers deux étapes d’entraînement successives.</p> <h3 id="16-beaucoup-de-sujets-récents-de-recherche-utilisent-les-fonctions-dinfluence-pour-déterminer-les-données-utiles-quon-peut-utiliser-pour-fine-tuner-le-modèle-pour-améliorer-la-génération-dun-llm-ou-ajouter-une-connaissance-au-modèle-par-exemple">1.6 Beaucoup de sujets récents de recherche utilisent les fonctions d’influence pour déterminer les données utiles (qu’on peut utiliser pour fine-tuner le modèle) pour améliorer la génération d’un LLM, ou ajouter une “connaissance” au modèle par exemple</h3> <h2 id="2-mesurer-sur-quelles-parties-de-linput-le-modèle-sest-basé-pour-faire-sa-prédiction-les-cartes-de-saillance-saliency-maps">2. Mesurer sur quelles parties de l’input le modèle s’est basé pour faire sa prédiction: les cartes de saillance (saliency maps)</h2> <ul> <li><strong>Objectif</strong> : voir comment la <strong>sortie</strong> du modèle $f(x)$ varie si on modifie chaque composante $x_i$ de l’entrée.</li> <li><strong>Formule</strong> : \(S_i(x) \;=\; \frac{\partial\,f(x)}{\partial\,x_i} \quad\Longrightarrow\quad \text{Carte }S(x) = [S_1(x), S_2(x), \dots]\)</li> <li>Application : <ul> <li>Pour une image, chaque $x_i$ est un pixel / un patch de l’image ;</li> <li>Pour du texte, chaque $x_i$ est un token.</li> </ul> </li> </ul> <p>Le résultat est une carte où chaque valeur $S_i(x)$ indique l’importance du pixel (ou du token) $i$ pour la prédiction du modèle.</p> <h2 id="3-mesurer-la-contribution-de-chaque-feature-de-linput-sur-la-prédiction-du-modèle-les-valeurs-de-shapley">3. Mesurer la contribution de chaque feature de l’input sur la prédiction du modèle: Les valeurs de shapley</h2> <p>[A FINIR]</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="XAI"/><summary type="html"><![CDATA[Méthodes d'explicabilité de la génération de texte par les LLMs]]></summary></entry><entry><title type="html">a post with plotly.js</title><link href="https://camillebrl.github.io/blog/2025/plotly/" rel="alternate" type="text/html" title="a post with plotly.js"/><published>2025-03-26T14:24:00+00:00</published><updated>2025-03-26T14:24:00+00:00</updated><id>https://camillebrl.github.io/blog/2025/plotly</id><content type="html" xml:base="https://camillebrl.github.io/blog/2025/plotly/"><![CDATA[<p>This is an example post with some <a href="https://plotly.com/javascript/">plotly</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}
</code></pre> <p>Also another example chart.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>This is how it looks like:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included plotly.js code could look like]]></summary></entry><entry><title type="html">a post with image galleries</title><link href="https://camillebrl.github.io/blog/2024/photo-gallery/" rel="alternate" type="text/html" title="a post with image galleries"/><published>2024-12-04T01:59:00+00:00</published><updated>2024-12-04T01:59:00+00:00</updated><id>https://camillebrl.github.io/blog/2024/photo-gallery</id><content type="html" xml:base="https://camillebrl.github.io/blog/2024/photo-gallery/"><![CDATA[<p>The images in this post are all zoomable, arranged into different mini-galleries using different libraries.</p> <h2 id="lightbox2"><a href="https://lokeshdhakar.com/projects/lightbox2/">Lightbox2</a></h2> <p><a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p> <hr/> <h2 id="photoswipe"><a href="https://photoswipe.com/">PhotoSwipe</a></h2> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--getting-started"> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-pswp-width="1669" data-pswp-height="2500" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg" alt=""/> </a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-2500.jpg" data-pswp-width="1875" data-pswp-height="2500" data-cropped="true" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-200.jpg" alt=""/> </a> <a href="https://unsplash.com" data-pswp-src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1666" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg" alt=""/> </a> <div> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1667" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg" alt=""/> </a> </div> </div> <hr/> <h2 id="spotlight-js"><a href="https://nextapps-de.github.io/spotlight/">Spotlight JS</a></h2> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/> </a> </div> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg"/> </a> </div> <hr/> <h2 id="venobox"><a href="https://veno.es/venobox/">Venobox</a></h2> <p><a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what included image galleries could look like]]></summary></entry><entry><title type="html">a post with tabs</title><link href="https://camillebrl.github.io/blog/2024/tabs/" rel="alternate" type="text/html" title="a post with tabs"/><published>2024-05-01T00:32:13+00:00</published><updated>2024-05-01T00:32:13+00:00</updated><id>https://camillebrl.github.io/blog/2024/tabs</id><content type="html" xml:base="https://camillebrl.github.io/blog/2024/tabs/"><![CDATA[<p>This is how a post with <a href="https://github.com/Ovski4/jekyll-tabs">tabs</a> looks like. Note that the tabs could be used for different purposes, not only for code.</p> <h2 id="first-tabs">First tabs</h2> <p>To add tabs, use the following syntax:</p> <div class="language-liquid highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">{%</span><span class="w"> </span><span class="nt">tabs</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-1</span><span class="w"> </span><span class="cp">%}</span>

Content 1

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-2</span><span class="w"> </span><span class="cp">%}</span>

Content 2

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtabs</span><span class="w"> </span><span class="cp">%}</span>
</code></pre></div></div> <p>With this you can generate visualizations like:</p> <ul id="log" class="tab" data-tab="ef2b8d76-3dbe-4046-ac6c-3021cd59f729" data-name="log"> <li class="active" id="log-php"> <a href="#">php </a> </li> <li id="log-js"> <a href="#">js </a> </li> <li id="log-ruby"> <a href="#">ruby </a> </li> </ul> <ul class="tab-content" id="ef2b8d76-3dbe-4046-ac6c-3021cd59f729" data-name="log"> <li class="active"> <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">var_dump</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">hello</span><span class="dl">"</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">pputs</span> <span class="dl">'</span><span class="s1">hello</span><span class="dl">'</span>
</code></pre></div></div> </li> </ul> <h2 id="another-example">Another example</h2> <ul id="data-struct" class="tab" data-tab="51cef969-8a35-4dbd-9753-6fa65e2691ce" data-name="data-struct"> <li class="active" id="data-struct-yaml"> <a href="#">yaml </a> </li> <li id="data-struct-json"> <a href="#">json </a> </li> </ul> <ul class="tab-content" id="51cef969-8a35-4dbd-9753-6fa65e2691ce" data-name="data-struct"> <li class="active"> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">hello</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">whatsup"</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">hi"</span>
</code></pre></div></div> </li> <li> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"hello"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"whatsup"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hi"</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> </li> </ul> <h2 id="tabs-for-something-else">Tabs for something else</h2> <ul id="something-else" class="tab" data-tab="0b80a8eb-472c-4e48-8331-a67824057811" data-name="something-else"> <li class="active" id="something-else-text"> <a href="#">text </a> </li> <li id="something-else-quote"> <a href="#">quote </a> </li> <li id="something-else-list"> <a href="#">list </a> </li> </ul> <ul class="tab-content" id="0b80a8eb-472c-4e48-8331-a67824057811" data-name="something-else"> <li class="active"> <p>Regular text</p> </li> <li> <blockquote> <p>A quote</p> </blockquote> </li> <li> <p>Hipster list</p> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included tabs in a post could look like]]></summary></entry><entry><title type="html">a post with typograms</title><link href="https://camillebrl.github.io/blog/2024/typograms/" rel="alternate" type="text/html" title="a post with typograms"/><published>2024-04-29T23:36:10+00:00</published><updated>2024-04-29T23:36:10+00:00</updated><id>https://camillebrl.github.io/blog/2024/typograms</id><content type="html" xml:base="https://camillebrl.github.io/blog/2024/typograms/"><![CDATA[<p>This is an example post with some <a href="https://github.com/google/typograms/">typograms</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">+----+
|    |---&gt; My first diagram!
+----+</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-typograms">+----+
|    |---&gt; My first diagram!
+----+
</code></pre> <p>Another example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.</span>
<span class="p">```</span>
</code></pre></div></div> <p>which generates:</p> <pre><code class="language-typograms">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.
</code></pre> <p>For more examples, check out the <a href="https://google.github.io/typograms/#examples">typograms documentation</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[this is what included typograms code could look like]]></summary></entry><entry><title type="html">a post that can be cited</title><link href="https://camillebrl.github.io/blog/2024/post-citation/" rel="alternate" type="text/html" title="a post that can be cited"/><published>2024-04-28T15:06:00+00:00</published><updated>2024-04-28T15:06:00+00:00</updated><id>https://camillebrl.github.io/blog/2024/post-citation</id><content type="html" xml:base="https://camillebrl.github.io/blog/2024/post-citation/"><![CDATA[<p>This is an example post that can be cited. The content of the post ends here, while the citation information is automatically provided below. The only thing needed is for you to set the <code class="language-plaintext highlighter-rouge">citation</code> key in the front matter to <code class="language-plaintext highlighter-rouge">true</code>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="citation"/><summary type="html"><![CDATA[this is what a post that can be cited looks like]]></summary></entry><entry><title type="html">a post with pseudo code</title><link href="https://camillebrl.github.io/blog/2024/pseudocode/" rel="alternate" type="text/html" title="a post with pseudo code"/><published>2024-04-15T00:01:00+00:00</published><updated>2024-04-15T00:01:00+00:00</updated><id>https://camillebrl.github.io/blog/2024/pseudocode</id><content type="html" xml:base="https://camillebrl.github.io/blog/2024/pseudocode/"><![CDATA[<p>This is an example post with some pseudo code rendered by <a href="https://github.com/SaswatPadhi/pseudocode.js">pseudocode</a>. The example presented here is the same as the one in the <a href="https://saswat.padhi.me/pseudocode.js/">pseudocode.js</a> documentation, with only one simple but important change: everytime you would use <code class="language-plaintext highlighter-rouge">$</code>, you should use <code class="language-plaintext highlighter-rouge">$$</code> instead. Also, note that the <code class="language-plaintext highlighter-rouge">pseudocode</code> key in the front matter is set to <code class="language-plaintext highlighter-rouge">true</code> to enable the rendering of pseudo code. As an example, using this code:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">pseudocode
</span><span class="sb">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Generates:</p> <pre><code class="language-pseudocode">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included pseudo code could look like]]></summary></entry><entry><title type="html">a post with code diff</title><link href="https://camillebrl.github.io/blog/2024/code-diff/" rel="alternate" type="text/html" title="a post with code diff"/><published>2024-01-27T19:22:00+00:00</published><updated>2024-01-27T19:22:00+00:00</updated><id>https://camillebrl.github.io/blog/2024/code-diff</id><content type="html" xml:base="https://camillebrl.github.io/blog/2024/code-diff/"><![CDATA[<p>You can display diff code by using the regular markdown syntax:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff
</span><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")
</span></code></pre></div></div> <p>But this is difficult to read, specially if you have a large diff. You can use <a href="https://diff2html.xyz/">diff2html</a> to display a more readable version of the diff. For this, just use <code class="language-plaintext highlighter-rouge">diff2html</code> instead of <code class="language-plaintext highlighter-rouge">diff</code> for the code block language:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff2html
</span><span class="sb">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
--- a/sample.js
+++ b/sample.js
@@ -1 +1 @@
-console.log("Hello World!")
+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>If we use a longer example, for example <a href="https://github.com/rtfpessoa/diff2html/commit/c2c253d3e3f8b8b267f551e659f72b44ca2ac927">this commit from diff2html</a>, it will generate the following output:</p> <pre><code class="language-diff2html">From 2aaae31cc2a37bfff83430c2c914b140bee59b6a Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sun, 9 Oct 2016 16:41:54 +0100
Subject: [PATCH 1/2] Initial template override support

---
 scripts/hulk.js                    |  4 ++--
 src/diff2html.js                   |  3 +--
 src/file-list-printer.js           | 11 ++++++++---
 src/hoganjs-utils.js               | 29 +++++++++++++++++------------
 src/html-printer.js                |  6 ++++++
 src/line-by-line-printer.js        |  6 +++++-
 src/side-by-side-printer.js        |  6 +++++-
 test/file-list-printer-tests.js    |  2 +-
 test/hogan-cache-tests.js          | 18 +++++++++++++++---
 test/line-by-line-tests.js         |  3 +--
 test/side-by-side-printer-tests.js |  3 +--
 11 files changed, 62 insertions(+), 29 deletions(-)

diff --git a/scripts/hulk.js b/scripts/hulk.js
index 5a793c18..a4b1a4d5 100755
--- a/scripts/hulk.js
+++ b/scripts/hulk.js
@@ -173,11 +173,11 @@ function namespace(name) {
 // write a template foreach file that matches template extension
 templates = extractFiles(options.argv.remain)
   .map(function(file) {
-    var openedFile = fs.readFileSync(file, 'utf-8');
+    var openedFile = fs.readFileSync(file, 'utf-8').trim();
     var name;
     if (!openedFile) return;
     name = namespace(path.basename(file).replace(/\..*$/, ''));
-    openedFile = removeByteOrderMark(openedFile.trim());
+    openedFile = removeByteOrderMark(openedFile);
     openedFile = wrap(file, name, openedFile);
     if (!options.outputdir) return openedFile;
     fs.writeFileSync(path.join(options.outputdir, name + '.js')
diff --git a/src/diff2html.js b/src/diff2html.js
index 21b0119e..64e138f5 100644
--- a/src/diff2html.js
+++ b/src/diff2html.js
@@ -7,7 +7,6 @@

 (function() {
   var diffParser = require('./diff-parser.js').DiffParser;
-  var fileLister = require('./file-list-printer.js').FileListPrinter;
   var htmlPrinter = require('./html-printer.js').HtmlPrinter;

   function Diff2Html() {
@@ -43,7 +42,7 @@

     var fileList = '';
     if (configOrEmpty.showFiles === true) {
-      fileList = fileLister.generateFileList(diffJson, configOrEmpty);
+      fileList = htmlPrinter.generateFileListSummary(diffJson, configOrEmpty);
     }

     var diffOutput = '';
diff --git a/src/file-list-printer.js b/src/file-list-printer.js
index e408d9b2..1e0a2c61 100644
--- a/src/file-list-printer.js
+++ b/src/file-list-printer.js
@@ -8,11 +8,16 @@
 (function() {
   var printerUtils = require('./printer-utils.js').PrinterUtils;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var baseTemplatesPath = 'file-summary';
   var iconsBaseTemplatesPath = 'icon';

-  function FileListPrinter() {
+  function FileListPrinter(config) {
+    this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   FileListPrinter.prototype.generateFileList = function(diffFiles) {
@@ -38,5 +43,5 @@
     });
   };

-  module.exports.FileListPrinter = new FileListPrinter();
+  module.exports.FileListPrinter = FileListPrinter;
 })();
diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 9949e5fa..0dda08d7 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -8,18 +8,19 @@
 (function() {
   var fs = require('fs');
   var path = require('path');
-
   var hogan = require('hogan.js');

   var hoganTemplates = require('./templates/diff2html-templates.js');

-  var templatesPath = path.resolve(__dirname, 'templates');
+  var extraTemplates;

-  function HoganJsUtils() {
+  function HoganJsUtils(configuration) {
+    this.config = configuration || {};
+    extraTemplates = this.config.templates || {};
   }

-  HoganJsUtils.prototype.render = function(namespace, view, params, configuration) {
-    var template = this.template(namespace, view, configuration);
+  HoganJsUtils.prototype.render = function(namespace, view, params) {
+    var template = this.template(namespace, view);
     if (template) {
       return template.render(params);
     }
@@ -27,17 +28,16 @@
     return null;
   };

-  HoganJsUtils.prototype.template = function(namespace, view, configuration) {
-    var config = configuration || {};
+  HoganJsUtils.prototype.template = function(namespace, view) {
     var templateKey = this._templateKey(namespace, view);

-    return this._getTemplate(templateKey, config);
+    return this._getTemplate(templateKey);
   };

-  HoganJsUtils.prototype._getTemplate = function(templateKey, config) {
+  HoganJsUtils.prototype._getTemplate = function(templateKey) {
     var template;

-    if (!config.noCache) {
+    if (!this.config.noCache) {
       template = this._readFromCache(templateKey);
     }

@@ -53,6 +53,7 @@

     try {
       if (fs.readFileSync) {
+        var templatesPath = path.resolve(__dirname, 'templates');
         var templatePath = path.join(templatesPath, templateKey);
         var templateContent = fs.readFileSync(templatePath + '.mustache', 'utf8');
         template = hogan.compile(templateContent);
@@ -66,12 +67,16 @@
   };

   HoganJsUtils.prototype._readFromCache = function(templateKey) {
-    return hoganTemplates[templateKey];
+    return extraTemplates[templateKey] || hoganTemplates[templateKey];
   };

   HoganJsUtils.prototype._templateKey = function(namespace, view) {
     return namespace + '-' + view;
   };

-  module.exports.HoganJsUtils = new HoganJsUtils();
+  HoganJsUtils.prototype.compile = function(templateStr) {
+    return hogan.compile(templateStr);
+  };
+
+  module.exports.HoganJsUtils = HoganJsUtils;
 })();
diff --git a/src/html-printer.js b/src/html-printer.js
index 585d5b66..13f83047 100644
--- a/src/html-printer.js
+++ b/src/html-printer.js
@@ -8,6 +8,7 @@
 (function() {
   var LineByLinePrinter = require('./line-by-line-printer.js').LineByLinePrinter;
   var SideBySidePrinter = require('./side-by-side-printer.js').SideBySidePrinter;
+  var FileListPrinter = require('./file-list-printer.js').FileListPrinter;

   function HtmlPrinter() {
   }
@@ -22,5 +23,10 @@
     return sideBySidePrinter.generateSideBySideJsonHtml(diffFiles);
   };

+  HtmlPrinter.prototype.generateFileListSummary = function(diffJson, config) {
+    var fileListPrinter = new FileListPrinter(config);
+    return fileListPrinter.generateFileList(diffJson);
+  };
+
   module.exports.HtmlPrinter = new HtmlPrinter();
 })();
diff --git a/src/line-by-line-printer.js b/src/line-by-line-printer.js
index b07eb53c..d230bedd 100644
--- a/src/line-by-line-printer.js
+++ b/src/line-by-line-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'line-by-line';
   var iconsBaseTemplatesPath = 'icon';
@@ -19,6 +20,9 @@

   function LineByLinePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   LineByLinePrinter.prototype.makeFileDiffHtml = function(file, diffs) {
diff --git a/src/side-by-side-printer.js b/src/side-by-side-printer.js
index bbf1dc8d..5e3033b3 100644
--- a/src/side-by-side-printer.js
+++ b/src/side-by-side-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'side-by-side';
   var iconsBaseTemplatesPath = 'icon';
@@ -26,6 +27,9 @@

   function SideBySidePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   SideBySidePrinter.prototype.makeDiffHtml = function(file, diffs) {
diff --git a/test/file-list-printer-tests.js b/test/file-list-printer-tests.js
index a502a46f..60ea3208 100644
--- a/test/file-list-printer-tests.js
+++ b/test/file-list-printer-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var fileListPrinter = require('../src/file-list-printer.js').FileListPrinter;
+var fileListPrinter = new (require('../src/file-list-printer.js').FileListPrinter)();

 describe('FileListPrinter', function() {
   describe('generateFileList', function() {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 190bf6f8..3bb754ac 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var HoganJsUtils = require('../src/hoganjs-utils.js').HoganJsUtils;
+var HoganJsUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)();
 var diffParser = require('../src/diff-parser.js').DiffParser;

 describe('HoganJsUtils', function() {
@@ -21,16 +21,28 @@ describe('HoganJsUtils', function() {
       });
       assert.equal(emptyDiffHtml, result);
     });
+
     it('should render view without cache', function() {
       var result = HoganJsUtils.render('generic', 'empty-diff', {
         contentClass: 'd2h-code-line',
         diffParser: diffParser
       }, {noCache: true});
-      assert.equal(emptyDiffHtml + '\n', result);
+      assert.equal(emptyDiffHtml, result);
     });
+
     it('should return null if template is missing', function() {
-      var result = HoganJsUtils.render('generic', 'missing-template', {}, {noCache: true});
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)({noCache: true});
+      var result = hoganUtils.render('generic', 'missing-template', {});
       assert.equal(null, result);
     });
+
+    it('should allow templates to be overridden', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+
+      var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
diff --git a/test/line-by-line-tests.js b/test/line-by-line-tests.js
index 1cd92073..8869b3df 100644
--- a/test/line-by-line-tests.js
+++ b/test/line-by-line-tests.js
@@ -14,7 +14,7 @@ describe('LineByLinePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expected, fileHtml);
     });
@@ -422,7 +422,6 @@ describe('LineByLinePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                &lt;/tbody&gt;\n' +
         '            &lt;/table&gt;\n' +
         '        &lt;/div&gt;\n' +
diff --git a/test/side-by-side-printer-tests.js b/test/side-by-side-printer-tests.js
index 76625f8e..771daaa5 100644
--- a/test/side-by-side-printer-tests.js
+++ b/test/side-by-side-printer-tests.js
@@ -14,7 +14,7 @@ describe('SideBySidePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expectedRight, fileHtml.right);
       assert.equal(expectedLeft, fileHtml.left);
@@ -324,7 +324,6 @@ describe('SideBySidePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                    &lt;/tbody&gt;\n' +
         '                &lt;/table&gt;\n' +
         '            &lt;/div&gt;\n' +

From f3cadb96677d0eb82fc2752dc3ffbf35ca9b5bdb Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sat, 15 Oct 2016 13:21:22 +0100
Subject: [PATCH 2/2] Allow uncompiled templates

---
 README.md                 |  3 +++
 src/hoganjs-utils.js      |  7 +++++++
 test/hogan-cache-tests.js | 24 +++++++++++++++++++++++-
 3 files changed, 33 insertions(+), 1 deletion(-)

diff --git a/README.md b/README.md
index 132c8a28..46909f25 100644
--- a/README.md
+++ b/README.md
@@ -98,6 +98,9 @@ The HTML output accepts a Javascript object with configuration. Possible options
   - `synchronisedScroll`: scroll both panes in side-by-side mode: `true` or `false`, default is `false`
   - `matchWordsThreshold`: similarity threshold for word matching, default is 0.25
   - `matchingMaxComparisons`: perform at most this much comparisons for line matching a block of changes, default is `2500`
+  - `templates`: object with previously compiled templates to replace parts of the html
+  - `rawTemplates`: object with raw not compiled templates to replace parts of the html
+  &gt; For more information regarding the possible templates look into [src/templates](https://github.com/rtfpessoa/diff2html/tree/master/src/templates)

 ## Diff2HtmlUI Helper

diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 0dda08d7..b2e9c275 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -17,6 +17,13 @@
   function HoganJsUtils(configuration) {
     this.config = configuration || {};
     extraTemplates = this.config.templates || {};
+
+    var rawTemplates = this.config.rawTemplates || {};
+    for (var templateName in rawTemplates) {
+      if (rawTemplates.hasOwnProperty(templateName)) {
+        if (!extraTemplates[templateName]) extraTemplates[templateName] = this.compile(rawTemplates[templateName]);
+      }
+    }
   }

   HoganJsUtils.prototype.render = function(namespace, view, params) {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 3bb754ac..a34839c0 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -36,7 +36,7 @@ describe('HoganJsUtils', function() {
       assert.equal(null, result);
     });

-    it('should allow templates to be overridden', function() {
+    it('should allow templates to be overridden with compiled templates', function() {
       var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');

       var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
@@ -44,5 +44,27 @@ describe('HoganJsUtils', function() {
       var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
       assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
     });
+
+    it('should allow templates to be overridden with uncompiled templates', function() {
+      var emptyDiffTemplate = '&lt;p&gt;&lt;/p&gt;';
+
+      var config = {rawTemplates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
+
+    it('should allow templates to be overridden giving priority to compiled templates', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+      var emptyDiffTemplateUncompiled = '&lt;p&gt;Not used!&lt;/p&gt;';
+
+      var config = {
+        templates: {'generic-empty-diff': emptyDiffTemplate},
+        rawTemplates: {'generic-empty-diff': emptyDiffTemplateUncompiled}
+      };
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is how you can display code diffs]]></summary></entry><entry><title type="html">a post with advanced image components</title><link href="https://camillebrl.github.io/blog/2024/advanced-images/" rel="alternate" type="text/html" title="a post with advanced image components"/><published>2024-01-27T11:46:00+00:00</published><updated>2024-01-27T11:46:00+00:00</updated><id>https://camillebrl.github.io/blog/2024/advanced-images</id><content type="html" xml:base="https://camillebrl.github.io/blog/2024/advanced-images/"><![CDATA[<p>This is an example post with advanced image components.</p> <h2 id="image-slider">Image Slider</h2> <p>This is a simple image slider. It uses the <a href="https://swiperjs.com/">Swiper</a> library. Check the <a href="https://swiperjs.com/demos">examples page</a> for more information of what you can achieve with it.</p> <swiper-container keyboard="true" navigation="true" pagination="true" pagination-clickable="true" pagination-dynamic-bullets="true" rewind="true"> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/9-480.webp 480w,/assets/img/9-800.webp 800w,/assets/img/9-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/9.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/7-480.webp 480w,/assets/img/7-800.webp 800w,/assets/img/7-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/7.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/8-480.webp 480w,/assets/img/8-800.webp 800w,/assets/img/8-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/8.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/10-480.webp 480w,/assets/img/10-800.webp 800w,/assets/img/10-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/10.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/12-480.webp 480w,/assets/img/12-800.webp 800w,/assets/img/12-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/12.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> </swiper-container> <h2 id="image-comparison-slider">Image Comparison Slider</h2> <p>This is a simple image comparison slider. It uses the <a href="https://img-comparison-slider.sneas.io/">img-comparison-slider</a> library. Check the <a href="https://img-comparison-slider.sneas.io/examples.html">examples page</a> for more information of what you can achieve with it.</p> <img-comparison-slider> <figure slot="first"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/prof_pic.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure slot="second"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic_color-480.webp 480w,/assets/img/prof_pic_color-800.webp 800w,/assets/img/prof_pic_color-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/prof_pic_color.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </img-comparison-slider>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what advanced image components could look like]]></summary></entry><entry><title type="html">a post with vega lite</title><link href="https://camillebrl.github.io/blog/2024/vega-lite/" rel="alternate" type="text/html" title="a post with vega lite"/><published>2024-01-27T00:20:00+00:00</published><updated>2024-01-27T00:20:00+00:00</updated><id>https://camillebrl.github.io/blog/2024/vega-lite</id><content type="html" xml:base="https://camillebrl.github.io/blog/2024/vega-lite/"><![CDATA[<p>This is an example post with some <a href="https://vega.github.io/vega-lite/">vega lite</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">vega_lite
</span><span class="sb">{
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "description": "A dot plot showing each movie in the database, and the difference from the average movie rating. The display is sorted by year to visualize everything in sequential order. The graph is for all Movies before 2019.",
  "data": {
    "url": "https://raw.githubusercontent.com/vega/vega/main/docs/data/movies.json"
  },
  "transform": [
    {"filter": "datum['IMDB Rating'] != null"},
    {"filter": {"timeUnit": "year", "field": "Release Date", "range": [null, 2019]}},
    {
      "joinaggregate": [{
        "op": "mean",
        "field": "IMDB Rating",
        "as": "AverageRating"
      }]
    },
    {
      "calculate": "datum['IMDB Rating'] - datum.AverageRating",
      "as": "RatingDelta"
    }
  ],
  "mark": "point",
  "encoding": {
    "x": {
      "field": "Release Date",
      "type": "temporal"
    },
    "y": {
      "field": "RatingDelta",
      "type": "quantitative",
      "title": "Rating Delta"
    },
    "color": {
      "field": "RatingDelta",
      "type": "quantitative",
      "scale": {"domainMid": 0},
      "title": "Rating Delta"
    }
  }
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-vega_lite">{
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "description": "A dot plot showing each movie in the database, and the difference from the average movie rating. The display is sorted by year to visualize everything in sequential order. The graph is for all Movies before 2019.",
  "data": {
    "url": "https://raw.githubusercontent.com/vega/vega/main/docs/data/movies.json"
  },
  "transform": [
    {"filter": "datum['IMDB Rating'] != null"},
    {"filter": {"timeUnit": "year", "field": "Release Date", "range": [null, 2019]}},
    {
      "joinaggregate": [{
        "op": "mean",
        "field": "IMDB Rating",
        "as": "AverageRating"
      }]
    },
    {
      "calculate": "datum['IMDB Rating'] - datum.AverageRating",
      "as": "RatingDelta"
    }
  ],
  "mark": "point",
  "encoding": {
    "x": {
      "field": "Release Date",
      "type": "temporal"
    },
    "y": {
      "field": "RatingDelta",
      "type": "quantitative",
      "title": "Rating Delta"
    },
    "color": {
      "field": "RatingDelta",
      "type": "quantitative",
      "scale": {"domainMid": 0},
      "title": "Rating Delta"
    }
  }
}
</code></pre> <p>This plot supports both light and dark themes.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included vega lite code could look like]]></summary></entry></feed>